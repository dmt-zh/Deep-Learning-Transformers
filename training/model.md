Архитектура:\
vocab: 26\
num_units: 4\
num_layers: 1\
num_heads: 2\
ffn_inner_dim: 1\
maximum_relative_position: 8


```python
model.weights=[[



EMBEDDINGS
===========================================================================================================
    <tf.Variable 'embedding:0' shape=(26, 4) dtype=float32, numpy=
        array([[ 0.14671177,  0.0053747 ,  0.06736612,  0.24799055],
            [-0.31832922, -0.02981016,  0.24268919, -0.00883007],
            [ 0.16466087, -0.19355544,  0.13758624, -0.24815826],
            [ 0.12503532, -0.20405605,  0.09287702, -0.01509858],
            [ 0.32633087,  0.39575705, -0.36188975,  0.05330939],
            [-0.05760631, -0.44611707, -0.02918044,  0.20692909],
            [ 0.4428975 ,  0.41633394, -0.42096657,  0.18396848],
            [-0.2990815 , -0.00918872, -0.35853025,  0.37610996],
            [ 0.28886628,  0.3446471 , -0.33046287, -0.35422695],
            [-0.05273629, -0.09677054, -0.07989597,  0.09643636],
            [-0.00317451, -0.12562251, -0.07696643,  0.3565591 ],
            [-0.24969372,  0.42842343,  0.33965686,  0.04512957],
            [-0.3355024 , -0.12055883, -0.27569625,  0.25504738],
            [ 0.05766013,  0.32848296, -0.08659133,  0.39373237],
            [-0.032702  ,  0.26997313,  0.05467943,  0.4087475 ],
            [-0.26891592,  0.1277629 , -0.29581347, -0.08838691],
            [-0.40115142,  0.3848703 , -0.21719521,  0.30619043],
            [ 0.36544216, -0.3013998 ,  0.24061537, -0.38344187],
            [-0.21665075,  0.16868848,  0.25376445,  0.28036726],
            [-0.16260293, -0.15875551,  0.15540385, -0.1515361 ],
            [-0.37329295, -0.02873805,  0.26479793, -0.43393177],
            [ 0.24502021, -0.2126259 ,  0.18423033,  0.17614162],
            [-0.2458734 ,  0.07098562, -0.10959095,  0.01534575],
            [-0.20285371,  0.32923263, -0.2766725 ,  0.24810028],
            [ 0.39961088, -0.00290391, -0.20099579, -0.33804166],
            [ 0.22136223,  0.08785087, -0.36695844,  0.42059255]],
            dtype=float32)>,
    <tf.Variable 'embedding:0' shape=(26, 4) dtype=float32, numpy=
        array([[ 0.426385  , -0.42090976, -0.23256385, -0.26911724],
            [ 0.2832037 , -0.01961613,  0.37301776, -0.37678877],
            [ 0.22005731, -0.37639123, -0.21890755,  0.4305262 ],
            [ 0.3281203 , -0.33153203,  0.18845421, -0.42431238],
            [-0.08146054,  0.25250992, -0.38676366,  0.43342203],
            [-0.11376222,  0.2148101 ,  0.44675848,  0.04583039],
            [-0.20417382,  0.33322066,  0.39263123,  0.08733767],
            [ 0.07841122,  0.40473628,  0.30672312,  0.0150696 ],
            [-0.12931362,  0.344729  , -0.01515096, -0.05739722],
            [ 0.00779376, -0.17039463,  0.08640301, -0.09533142],
            [-0.4060275 ,  0.3711171 ,  0.23874152, -0.39585766],
            [-0.01569701, -0.37052655, -0.07332542,  0.4315061 ],
            [ 0.03994491, -0.13137273, -0.18395868,  0.1682282 ],
            [-0.08962154,  0.05518335,  0.10828632,  0.03638056],
            [ 0.12179808,  0.18239447,  0.14524622, -0.35716793],
            [-0.3982386 ,  0.41264606, -0.0276975 ,  0.0086441 ],
            [ 0.0162445 , -0.06555927,  0.35321307, -0.44710612],
            [-0.12210616, -0.04789627, -0.22348994, -0.0050126 ],
            [-0.19536465, -0.36221802, -0.26946855, -0.15109178],
            [-0.08454251,  0.18201673, -0.11034724, -0.20568298],
            [-0.42216015, -0.23068035,  0.44658333, -0.06286138],
            [ 0.03794643,  0.2001586 , -0.08569673,  0.27832872],
            [-0.2896335 ,  0.43570405, -0.3836738 ,  0.37995166],
            [ 0.42532814, -0.2240399 ,  0.11501598, -0.2002266 ],
            [-0.19803494, -0.11987698,  0.02486098, -0.2921996 ],
            [ 0.04140786,  0.0807289 , -0.19615251, -0.11633505]],
            dtype=float32)>,

ENCODER_LAYER_NORM
===========================================================================================================
    <tf.Variable 'attention_encoder/layer_norm/gamma:0' shape=(4,) dtype=float32, numpy=
        array([0.9999    , 1.0000998 , 0.99990004, 0.9999    ], dtype=float32)>,
    
    <tf.Variable 'attention_encoder/layer_norm/beta:0' shape=(4,) dtype=float32, numpy=
        array([-9.9997560e-05, -9.9995348e-05, -9.9985344e-05, -9.9997589e-05], dtype=float32)>,

 ENCODER_RELATIVE_POSITION_KEYS
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'relative_position_keys:0' shape=(17, 4) dtype=float32, numpy=
        array([[ 0.08976793,  0.16718584, -0.39001435,  0.16318727],
            [-0.16895139,  0.05802131,  0.47831494,  0.04198796],
            [ 0.32562828,  0.3162663 , -0.31268013, -0.37275475],
            [ 0.10602236,  0.4337268 ,  0.3854707 , -0.2275095 ],
            [ 0.51570004,  0.21096867,  0.39602798,  0.14997292],
            [-0.3365597 , -0.16287798,  0.32378793, -0.04594088],
            [-0.06974286, -0.17595881, -0.284577  ,  0.43483847],
            [ 0.24058351,  0.5246523 ,  0.00247441, -0.5336145 ],
            [-0.29480794, -0.12507348, -0.35026762, -0.07830925],
            [-0.2973441 , -0.26286048, -0.5083273 , -0.2852661 ],
            [ 0.17994797, -0.36410576,  0.09732419,  0.09097195],
            [ 0.04637545,  0.2022031 ,  0.21048772, -0.23328876],
            [-0.12462941, -0.301556  , -0.04866835, -0.40888056],
            [ 0.18591392,  0.39386457, -0.46152097, -0.02579963],
            [ 0.12222564,  0.2318505 , -0.02114463,  0.35813963],
            [ 0.14413434, -0.21323007,  0.3873285 , -0.06416991],
            [-0.18756926, -0.3476953 , -0.32044005, -0.35976273]],
            dtype=float32)>

 ENCODER_RELATIVE_POSITION_VALUES
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'relative_position_values:0' shape=(17, 4) dtype=float32, numpy=
        array([[ 3.90476584e-02, -5.43521643e-02,  3.53632212e-01, -1.73419595e-01],
            [-2.18946159e-01,  2.12962985e-01,  3.04933190e-01, -1.40922874e-01],
            [-4.16319609e-01,  2.95455217e-01, -2.27786303e-02,  1.86786413e-01],
            [-2.25924134e-01,  3.00490320e-01,  3.48576069e-01,  8.57476592e-02],
            [-3.88604224e-01,  3.04124057e-01,  2.58833170e-02, -6.37429953e-03],
            [ 3.92216861e-01,  4.53911781e-01,  4.36388791e-01, -3.04618001e-01],
            [ 4.85731423e-01, -2.93636233e-01, -2.71892399e-01,  2.19621301e-01],
            [-3.34709436e-01,  3.54591370e-01,  5.19296825e-01,  2.11471736e-01],
            [-3.73757899e-01, -1.46695837e-01, -1.86237440e-01, -3.40131074e-01],
            [-2.96162009e-01, -5.10839880e-01,  1.51660636e-01, -3.11320096e-01],
            [-3.60454619e-01,  3.31580877e-01, -3.46160293e-01,  1.62531853e-01],
            [ 9.08172727e-02,  2.43266821e-02, -3.23041499e-01,  1.25872493e-02],
            [-4.18499887e-01, -1.49279356e-01, -1.09086037e-02, -2.27653891e-01],
            [ 2.09907234e-01, -2.42165595e-01, -1.59413815e-02,  2.59240389e-01],
            [ 2.46307254e-01, -4.23015445e-01, -3.04849327e-01, -1.81657702e-01],
            [-3.39775681e-01, -4.29110646e-01, -6.88990951e-02, -1.19805336e-04],
            [ 4.04176652e-01, -5.27261198e-01,  2.43623018e-01, -4.18073058e-01]],
            dtype=float32)>

 ENCODER_MULTIHEAD_ATTENTION_QUERIES
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_encoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.14534347,  0.27083942, -0.6319943 ,  0.26449245],
            [-0.27363282,  0.09390584,  0.7750585 ,  0.06792836],
            [ 0.52748376,  0.51250833, -0.5065011 , -0.6040277 ],
            [ 0.1716762 ,  0.7028169 ,  0.6244341 , -0.36850765]],
            dtype=float32)>,
      
    <tf.Variable 'attention_encoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([-9.9469231e-05,  9.8410994e-05, -9.9723839e-05,  9.9739998e-05], dtype=float32)>,

 ENCODER_MULTIHEAD_ATTENTION_KEYS
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_encoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.06316626, -0.08797874,  0.5730487 , -0.28087333],
            [-0.3548331 ,  0.34493956,  0.4941478 , -0.22822139],
            [-0.6744151 ,  0.47879195, -0.0370052 ,  0.30252886],
            [-0.36593965,  0.4869491 ,  0.56465846,  0.13882793]],
            dtype=float32)>,
      
    <tf.Variable 'attention_encoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([0., 0., 0., 0.], dtype=float32)>,

 ENCODER_MULTIHEAD_ATTENTION_VALUES
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_encoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.59671724,  0.61192864,  0.07371567,  0.42274275],
            [-0.06614358,  0.31821427,  0.23728046, -0.25056398],
            [ 0.83594275, -0.61379325,  0.68638164,  0.32775593],
            [-0.11788318,  0.50625724,  0.64237195,  0.37022194]],
            dtype=float32)>,
      
    <tf.Variable 'attention_encoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([9.998207e-05, 9.983983e-05, 9.999396e-05, 9.974574e-05], dtype=float32)>,

 ENCODER_MULTIHEAD_ATTENTION_OUTPUT
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_encoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.46561518,  0.3955029 ,  0.7604489 ,  0.4968639 ],
            [-0.6453096 ,  0.15844761, -0.2996253 ,  0.02333054],
            [-0.5605198 ,  0.41347507,  0.41461536, -0.5472681 ],
            [ 0.11319336, -0.49385372,  0.17530896, -0.14219047]],
            dtype=float32)>,
      
    <tf.Variable 'attention_encoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([-9.998642e-05,  9.998732e-05,  9.999270e-05, -9.999036e-05], dtype=float32)>,

 ENCODER_MULTIHEAD_ATTENTION_LAYER_NORM
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_encoder_layer/layer_norm/gamma:0' shape=(4,) dtype=float32, numpy=
        array([0.9999002, 1.0000998, 0.9999   , 1.0001   ], dtype=float32)>,
    
    <tf.Variable 'attention_encoder_layer/layer_norm/beta:0' shape=(4,) dtype=float32, numpy=
        array([9.998153e-05, 9.997114e-05, 9.999361e-05, 9.999008e-05], dtype=float32)>,
 
 ENCODER_MULTIHEAD_ATTENTION_FEED_FORWARD_NETWORK
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_encoder_layer/feed_forward_network/kernel:0' shape=(4, 1) dtype=float32,
        numpy=array([[ 0.3706186 ],
            [-0.34428796],
            [ 0.8504171 ],
            [ 0.6793597 ]],
            dtype=float32)>,
    
    <tf.Variable 'attention_encoder_layer/feed_forward_network/bias:0' shape=(1,) dtype=float32,
        numpy=array([9.999523e-05], dtype=float32)>,
    
    <tf.Variable 'attention_encoder_layer/feed_forward_network/kernel:0' shape=(1, 4) dtype=float32,
        numpy=array([[-0.58181024, -1.0542388 ,  1.0734876 ,  0.26240653]], dtype=float32)>,
      
    <tf.Variable 'attention_encoder_layer/feed_forward_network/bias:0' shape=(4,) dtype=float32,
        numpy=array([-9.9989666e-05,  9.9985009e-05,  9.9994839e-05, -9.9993682e-05], dtype=float32)>,

 ENCODER_MULTIHEAD_ATTENTION_FEED_FORWARD_NETWORK_LAYER_NORM
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_encoder_layer/layer_norm/gamma:0' shape=(4,) dtype=float32, numpy=
        array([0.9999    , 0.99990034, 0.99990004, 1.0001    ], dtype=float32)>,
    
    <tf.Variable 'attention_encoder_layer/layer_norm/beta:0' shape=(4,) dtype=float32, numpy=
        array([ 9.9987155e-05, -9.9986180e-05,  9.9994410e-05,  9.9992991e-05], dtype=float32)>,
 
 
DECODER_LAYER_NORM
===========================================================================================================
    <tf.Variable 'attention_decoder/layer_norm/gamma:0' shape=(4,) dtype=float32, numpy=
        array([0.9999, 1.0001, 0.9999, 0.9999], dtype=float32)>,
    
    <tf.Variable 'attention_decoder/layer_norm/beta:0' shape=(4,) dtype=float32, numpy=
        array([ 9.9995981e-05, -9.9998404e-05, -9.9986617e-05,  9.9999161e-05], dtype=float32)>,

 DECODER_RELATIVE_POSITION_KEYS
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'relative_position_keys:0' shape=(17, 4) dtype=float32, numpy=
        array([[ 2.7899134e-01, -2.0445585e-02,  1.2348890e-03, -3.6553001e-01],
            [-6.8583935e-02, -4.3044472e-01, -3.5147339e-02,  4.5154613e-01],
            [-3.1388864e-01,  3.8263863e-01, -4.5303053e-01, -5.3243476e-01],
            [-2.8136209e-01,  2.0053744e-02, -3.4160978e-01,  8.9547038e-03],
            [-3.5327512e-01,  3.8128507e-01,  4.9321157e-01,  7.6080441e-02],
            [-3.4785360e-01,  1.7003769e-01, -1.4376363e-01, -4.2595857e-01],
            [-2.9662433e-01, -2.2923261e-01,  3.5583973e-05, -1.8393454e-01],
            [-4.6876344e-01,  1.0573736e-01,  4.5210293e-01, -2.9274166e-01],
            [-2.6471275e-01, -3.4506640e-01, -4.8859006e-01, -2.7644020e-01],
            [-4.4009560e-01, -2.9544768e-01,  2.7102202e-01,  3.3576179e-01],
            [ 5.0487620e-01,  3.1887752e-01,  1.9042289e-01,  3.5298163e-01],
            [-2.9883975e-01, -1.4134929e-01, -1.2956911e-01,  5.0754017e-01],
            [-4.1630840e-01, -3.7364376e-01, -1.4588079e-01,  1.8797451e-01],
            [ 1.1813885e-01,  4.4629139e-01, -1.3614678e-01,  1.8647635e-01],
            [ 2.2723138e-01,  2.9188687e-01,  1.2117922e-02,  4.8553962e-01],
            [ 3.9999902e-02,  2.5057000e-01, -1.8810961e-01, -3.8095438e-01],
            [ 4.7852570e-01,  3.4346735e-01,  2.3742086e-01, -3.0368447e-02]],
            dtype=float32)>,

 DECODER_RELATIVE_POSITION_VALUES
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'custom_model_1/self_attention_decoder_1/self_attention_decoder_layer_1/transformer_layer_wrapper_7/multi_head_attention_4/relative_position_values:0' shape=(17, 4) dtype=float32, numpy=
        array([[ 0.3322038 , -0.02476621,  0.4476778 , -0.18773213],
            [-0.25491905, -0.14713672, -0.3957917 ,  0.5270013 ],
            [ 0.29878598, -0.13261658,  0.27900892, -0.09546232],
            [-0.1947166 , -0.20960644, -0.48086435, -0.03647462],
            [-0.05636662, -0.20659173, -0.16827178, -0.16243654],
            [ 0.51081175,  0.2600072 , -0.1381323 ,  0.1056602 ],
            [-0.12970802, -0.12108248,  0.01482713, -0.15967962],
            [-0.3014332 , -0.2964048 , -0.32640266, -0.27699274],
            [-0.06658583, -0.31086314,  0.4608132 , -0.49099422],
            [ 0.21693003, -0.05526388, -0.38180184, -0.11376667],
            [ 0.46607488,  0.10029   ,  0.45010996,  0.39739567],
            [ 0.27547067, -0.03516749,  0.03683221,  0.12048835],
            [ 0.33854204, -0.27465135, -0.28798658,  0.22028506],
            [ 0.49675447,  0.08991623,  0.33001387,  0.30448127],
            [ 0.4801914 ,  0.48811656,  0.04932785, -0.526579  ],
            [ 0.00770247, -0.28421357, -0.53414166,  0.44348848],
            [-0.17226687,  0.44507468,  0.03841287, -0.2732485 ]],
            dtype=float32)>

 DECODER_MULTIHEAD_ATTENTION_QUERIES
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_decoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.01099734, -0.7810495 , -0.73735577,  0.79891956],
        [ 0.73912656, -0.49013367,  0.8136611 ,  0.3165914 ],
        [-0.1051478 ,  0.02483633,  0.8216348 , -0.6652353 ],
        [-0.3981433 , -0.81823325,  0.02400015,  0.8290195 ]],
        dtype=float32)>,
    
    <tf.Variable 'attention_decoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([ 9.973272e-05,  9.985242e-05,  9.937238e-05, -9.989303e-05], dtype=float32)>,

 DECODER_MULTIHEAD_ATTENTION_KEYS
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_decoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[-0.27847373, -0.03214634, -0.73880833, -0.8213089 ],
        [-0.59721434, -0.3810854 ,  0.7220296 , -0.28589627],
        [-0.19510756,  0.43171954,  0.45056745, -0.17148761],
        [-0.14748909,  0.474493  , -0.6258725 ,  0.6993115 ]],
        dtype=float32)>,
      
    <tf.Variable 'attention_decoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([3.2037237e-09, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00], dtype=float32)>,

 DECODER_MULTIHEAD_ATTENTION_VALUES
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_decoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.45191762, -0.03302564,  0.0019008 , -0.59212637],
        [-0.11101868, -0.6975001 , -0.05684523,  0.7314883 ],
        [-0.50845766,  0.61984533, -0.7340933 , -0.8627429 ],
        [-0.4559587 ,  0.03259073, -0.55337113,  0.0146083 ]],
        dtype=float32)>,
    
    <tf.Variable 'attention_decoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([-9.996404e-05,  9.999791e-05,  9.999344e-05,  9.999351e-05], dtype=float32)>,

 DECODER_MULTIHEAD_ATTENTION_OUTPUT
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_decoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.5383316 , -0.04022584,  0.72522086, -0.3040608 ],
        [-0.41311604, -0.23828873, -0.6413558 ,  0.8539398 ],
        [ 0.4841886 , -0.2149634 ,  0.4519461 , -0.15456662],
        [-0.315377  , -0.33970127, -0.77898926, -0.05919567]],
        dtype=float32)>,

    <tf.Variable 'attention_decoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([ 9.999626e-05, -9.999852e-05, -9.998907e-05,  9.999799e-05], dtype=float32)>,

 DECODER_MULTIHEAD_ATTENTION_LAYER_NORM
 ----------------------------------------------------------------------------------------------------------  
    <tf.Variable 'attention_decoder_layer/layer_norm_11/gamma:0' shape=(4,) dtype=float32,
        numpy=array([0.9999    , 1.0001    , 0.9999    , 0.99990016], dtype=float32)>,
    
    <tf.Variable 'attention_decoder_layer/layer_norm_11/beta:0' shape=(4,) dtype=float32, numpy=
        array([-9.9992489e-05, -9.9995639e-05,  9.9986406e-05, -9.9985431e-05], dtype=float32)>,

 ENCODER_DECODER_MULTIHEAD_ATTENTION_QUERIES
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_decoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[ 0.29375896, -0.13212162,  0.44027263,  0.2791893 ],
        [-0.13651408,  0.0061353 ,  0.15497115, -0.8441047 ],
        [-0.60134655,  0.6982267 ,  0.85050595,  0.31245068],
        [ 0.40402174,  0.15626022, -0.26950866, -0.10568067]],
        dtype=float32)>,
      
    <tf.Variable 'attention_decoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([ 9.9885663e-05, -9.9860008e-05,  9.9198136e-05,  9.9844197e-05], dtype=float32)>,

 ENCODER_DECODER_MULTIHEAD_ATTENTION_KEYS
 ----------------------------------------------------------------------------------------------------------        
    <tf.Variable 'attention_decoder_layer/multi_head_attention/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[-0.5473371 , -0.04244068,  0.58298093,  0.15433362],
        [-0.47253197,  0.26827273,  0.6891823 ,  0.09035341],
        [ 0.21209545, -0.36606348,  0.6547235 ,  0.6372681 ],
        [-0.80494326,  0.45422682, -0.39818498,  0.05864402]],
        dtype=float32)>,
      
    <tf.Variable 'attention_decoder_layer/multi_head_attention/bias:0' shape=(4,) dtype=float32,
        numpy=array([0., 0., 0., 0.], dtype=float32)>,

 ENCODER_DECODER_MULTIHEAD_ATTENTION_VALUES
 ----------------------------------------------------------------------------------------------------------   
    <tf.Variable 'attention_decoder_layer/multi_head_attention/dense_28/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[-0.40625763, -0.24491705,  0.48668286, -0.40662423],
        [ 0.3320533 , -0.10792641,  0.64942926, -0.66827846],
        [ 0.7334444 , -0.29935077,  0.67398745,  0.19292124],
        [-0.3600851 , -0.18842734,  0.24539974, -0.6271439 ]],
        dtype=float32)>,
      
    <tf.Variable 'attention_decoder_layer/multi_head_attention/dense_28/bias:0' shape=(4,) dtype=float32,
        numpy=array([9.999478e-05, 9.999891e-05, 9.993316e-05, 9.999648e-05], dtype=float32)>,

 ENCODER_DECODER_MULTIHEAD_ATTENTION_OUTPUT
 ----------------------------------------------------------------------------------------------------------    
    <tf.Variable 'attention_decoder_layer/multi_head_attention/dense_29/kernel:0' shape=(4, 4) dtype=float32,
        numpy=array([[-0.54998374,  0.1245145 , -0.47193202,  0.5967043 ],
        [-0.7510944 , -0.8605494 , -0.5412126 ,  0.65565455],
        [ 0.3713164 , -0.09713312, -0.01553955, -0.18984386],
        [ 0.85407275, -0.24814881, -0.74078345, -0.08075736]],
        dtype=float32)>,
      
    <tf.Variable 'attention_decoder_layer/multi_head_attention/dense_29/bias:0' shape=(4,) dtype=float32,
        numpy=array([ 9.999620e-05, -9.999862e-05, -9.998479e-05,  9.999794e-05], dtype=float32)>,

 ENCODER_DECODER_MULTIHEAD_ATTENTION_LAYER_NORM
 ----------------------------------------------------------------------------------------------------------   
    <tf.Variable 'attention_decoder_layer/layer_norm_12/gamma:0' shape=(4,) dtype=float32,
        numpy=array([1.0000999 , 0.99990964, 0.99990034, 0.9999002 ], dtype=float32)>,
    
    <tf.Variable 'attention_decoder_layer/layer_norm_12/beta:0' shape=(4,) dtype=float32,
        numpy=array([ 9.9829071e-05, -9.9845245e-05, -9.9860961e-05,  9.9294084e-05], dtype=float32)>,

 DECODER_MULTIHEAD_ATTENTION_FEED_FORWARD_NETWORK
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_decoder_layer/feed_forward_network/kernel:0' shape=(4, 1) dtype=float32,
        numpy=array([[-0.2290949 ],
        [-0.00514491],
        [ 0.73377645],
        [ 0.6286779 ]],
        dtype=float32)>,
       
    <tf.Variable 'attention_decoder_layer/feed_forward_network/bias:0' shape=(1,) dtype=float32,
        numpy=array([9.99922e-05], dtype=float32)>,
 
    <tf.Variable 'attention_decoder_layer/feed_forward_network/kernel:0' shape=(1, 4) dtype=float32,
        numpy=array([[-0.81943625, -1.0281535 ,  0.5686009 ,  0.46244594]], dtype=float32)>,
      
    <tf.Variable 'attention_decoder_layer/feed_forward_network/bias:0' shape=(4,) dtype=float32,
        numpy=array([ 9.9996454e-05, -9.9998251e-05, -9.9988953e-05,  9.9997938e-05], dtype=float32)>,

 DECODER_MULTIHEAD_ATTENTION_FEED_FORWARD_NETWORK_LAYER_NORM
 ----------------------------------------------------------------------------------------------------------
    <tf.Variable 'attention_decoder_layer/layer_norm/gamma:0' shape=(4,) dtype=float32,
        numpy=array([1.0000999, 0.9999108, 1.0001   , 0.9999001], dtype=float32)>,
    
    <tf.Variable 'attention_decoder_layer/layer_norm/beta:0' shape=(4,) dtype=float32,
        numpy=array([-9.996590e-05, -9.853281e-05,  9.998935e-05,  9.998758e-05], dtype=float32)>,

 FIRST_HEAD_LAST_LAYER_DECODER_MULTIHEAD_ATTENTION_OUTPUT
 ---------------------------------------------------------------------------------------------------------- 
    <tf.Variable 'attention_decoder/kernel:0' shape=(4, 26) dtype=float32, numpy=
        array([[ 0.3822944 , -0.33581287,  0.23010997, -0.04402662, -0.27769452,
                -0.24065956,  0.02363644,  0.26989314, -0.21004504,  0.04684651,
                -0.39692408,  0.42392096, -0.20916374,  0.41334388, -0.22664912,
                0.20778146, -0.35328284,  0.4155799 , -0.13672668, -0.01718351,
                -0.06838436,  0.24445835,  0.21675876, -0.3351474 ,  0.05118383,
                0.03380965],
            [ 0.446844  , -0.28993335, -0.38898298,  0.24193081,  0.08514454,
                -0.4267032 , -0.07030203, -0.19679397, -0.32392362,  0.06029472,
                0.34389034, -0.32140544,  0.09693023,  0.23836383,  0.423027  ,
                -0.01423305,  0.2969577 ,  0.2863241 ,  0.14396343, -0.29054305,
                0.30611864,  0.12472185,  0.19431618, -0.23483412,  0.30025133,
                -0.41406745],
            [ 0.429428  ,  0.1002365 , -0.03606506, -0.10490506,  0.00789979,
                0.05887799,  0.4469482 , -0.33151114,  0.3710511 , -0.26535589,
                -0.2574946 , -0.22934832, -0.42932925, -0.40822604, -0.38177162,
                -0.14103958,  0.05426845, -0.4447134 ,  0.18378231, -0.24224198,
                -0.02116036, -0.19475666, -0.13605139, -0.4457667 , -0.33733746,
                0.3182632 ],
            [ 0.4021895 , -0.20659295,  0.4375638 ,  0.2795143 , -0.21198258,
                -0.38118714,  0.0108706 , -0.29614487, -0.30565634, -0.10337154,
                0.20457418, -0.09954488, -0.08411301, -0.19842063,  0.04822277,
                -0.26256427, -0.20370014, -0.25958145,  0.23261051, -0.0430963 ,
                0.21777047,  0.1625912 , -0.08861495, -0.21442075, -0.0123434 ,
                0.41044244]],
                dtype=float32)>,
         
    <tf.Variable 'attention_decoder/bias:0' shape=(26,) dtype=float32, numpy=
        array([-9.9992918e-05, -9.9995093e-05,  9.9999430e-05,  9.9980120e-05,
                9.9954741e-05, -9.9988436e-05, -9.9995828e-05, -9.9994330e-05,
            -9.9996643e-05,  9.9972480e-05,  9.9985453e-05, -9.9983430e-05,
                9.9983758e-05, -9.9992249e-05,  9.9995741e-05, -9.9993820e-05,
            -9.9991135e-05, -9.9992190e-05, -9.9992918e-05, -9.9993631e-05,
            -9.9990306e-05, -9.9991688e-05, -9.9992038e-05, -9.9991550e-05,
            -9.9989054e-05,  9.9996978e-05],
            dtype=float32)>
]]
```
