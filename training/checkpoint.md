```python
save_counter/.ATTRIBUTES/VARIABLE_VALUE
1
-----------------------------------------------------------------------------------------------------------
optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE
10
-----------------------------------------------------------------------------------------------------------
optimizer/beta_2/.ATTRIBUTES/VARIABLE_VALUE
0.998
-----------------------------------------------------------------------------------------------------------
optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE
0.9
-----------------------------------------------------------------------------------------------------------
model/examples_inputter/labels_inputter/embedding/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [7.5055832e-05, 1.5360570e-04, 2.3265678e-05, 4.2018637e-05],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [3.6290483e-06, 3.4320688e-05, 6.3079037e-06, 1.4353149e-05],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [7.3252813e-05, 3.3783726e-04, 1.9286507e-04, 1.8260926e-04],
       [4.2546390e-06, 1.0039026e-05, 6.7675887e-06, 3.7536010e-06],
       [2.2684802e-07, 2.6506834e-07, 9.0150058e-07, 1.2023841e-07],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [8.1206337e-05, 1.4922340e-05, 1.3434562e-05, 2.8221175e-05],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00],
       [5.5541441e-06, 3.4820648e-06, 3.6408514e-06, 2.0316851e-05]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/examples_inputter/features_inputter/embedding/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [1.86927548e-06, 1.56680528e-06, 1.16076981e-05, 1.01051992e-05],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [8.58371732e-06, 1.76828908e-05, 7.86651344e-06, 8.16596184e-06],
       [1.01991376e-04, 6.82630998e-05, 5.73538928e-05, 2.02699848e-05],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [9.68010681e-06, 3.22066467e-06, 7.28953455e-06, 8.09627727e-06],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [6.76340642e-05, 2.71768786e-05, 3.16293183e-04, 1.73776119e-04],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [3.11241238e-05, 1.45537151e-05, 9.09654432e-07, 7.89158821e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/examples_inputter/features_inputter/embedding/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.00288666,  0.0017942 , -0.00312338, -0.00305576],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.00799749, -0.0087382 ,  0.00168362, -0.00710765],
       [ 0.03465101, -0.01239833, -0.0117879 , -0.01291223],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.01004356, -0.00459474, -0.0062505 , -0.00252708],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.00331301, -0.01302194,  0.05812573, -0.03571965],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.0125816 , -0.01073221, -0.00197696,  0.0013382 ]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/examples_inputter/features_inputter/embedding/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.14671177,  0.0053747 ,  0.06736612,  0.24799055],
       [-0.31832922, -0.02981016,  0.24268919, -0.00883007],
       [ 0.16466087, -0.19355544,  0.13758624, -0.24815826],
       [ 0.12460893, -0.20424786,  0.09291431, -0.01493347],
       [ 0.32643086,  0.39565706, -0.36178982,  0.05320942],
       [-0.05760631, -0.44611707, -0.02918044,  0.20692909],
       [ 0.44299746,  0.41623396, -0.42106652,  0.18396848],
       [-0.29918146, -0.00908872, -0.35863024,  0.37601233],
       [ 0.28876632,  0.3446471 , -0.33056286, -0.354127  ],
       [-0.05303854, -0.09643465, -0.0798576 ,  0.09694889],
       [-0.00363803, -0.12569518, -0.07662742,  0.35695815],
       [-0.24959373,  0.42832345,  0.33975685,  0.04502958],
       [-0.33586848, -0.12059106, -0.2751742 ,  0.25537825],
       [ 0.05756015,  0.32858294, -0.08669132,  0.39373237],
       [-0.03260201,  0.27007312,  0.05457944,  0.4088474 ],
       [-0.26881593,  0.12786287, -0.29591346, -0.08848685],
       [-0.40105146,  0.3849702 , -0.21729517,  0.3062899 ],
       [ 0.36544216, -0.3013998 ,  0.24061537, -0.38344187],
       [-0.21665075,  0.16868848,  0.25376445,  0.28036726],
       [-0.16260293, -0.15875551,  0.15540385, -0.1515361 ],
       [-0.37329292, -0.02873805,  0.26479793, -0.43393177],
       [ 0.24531117, -0.21219078,  0.18380824,  0.17641887],
       [-0.2458734 ,  0.07098562, -0.10959095,  0.01534575],
       [-0.20285371,  0.32923263, -0.2766725 ,  0.24810028],
       [ 0.39961088, -0.00290391, -0.20099579, -0.33804166],
       [ 0.2210818 ,  0.08820486, -0.36702973,  0.42055228]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [3.0640092e-07, 9.9882573e-07],
       [2.5274198e-06, 2.7992057e-06],
       [2.1831340e-06, 2.8595618e-06],
       [2.1085680e-06, 2.4775190e-06],
       [1.5064992e-07, 9.7442421e-07],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/relative_position_keys/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [-1.3253276e-04, -7.5113261e-04],
       [ 3.8716428e-03,  7.0649578e-04],
       [-4.6160901e-03, -1.6448548e-04],
       [-7.1123912e-05,  1.4180185e-03],
       [ 9.5103669e-04, -1.2089313e-03],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/relative_position_keys/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.09437436,  0.17576498],
       [-0.41002786,  0.17156124],
       [-0.17762113,  0.06099868],
       [ 0.50285953,  0.04414254],
       [ 0.3423379 ,  0.33249545],
       [-0.32872528, -0.39188263],
       [ 0.11137925,  0.45595688],
       [ 0.4048462 , -0.23951651],
       [ 0.5426128 ,  0.22196943],
       [ 0.41597345,  0.1577042 ],
       [-0.3540977 , -0.17089236],
       [ 0.34040308, -0.04829836],
       [-0.0733217 , -0.18498814],
       [-0.2991801 ,  0.4571522 ],
       [ 0.25282407,  0.5516797 ],
       [ 0.00270569, -0.5611015 ],
       [-0.30983105, -0.13159618]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[5.8510559e-06, 1.8826961e-06, 1.4080581e-06, 1.0458541e-06],
       [3.6309957e-05, 1.2478776e-05, 1.1783437e-05, 7.1214522e-06],
       [7.9808497e-06, 1.2965135e-06, 2.7437607e-06, 2.7641538e-06],
       [3.9837469e-05, 1.0282936e-05, 1.5386813e-05, 1.2129181e-05]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_values/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.2929203 , -0.27242538,  0.67232776,  0.53718096],
       [ 0.05894516, -0.08902478, -0.6622835 , -0.83045983],
       [-0.8437257 , -0.53121954, -0.47724915,  0.84936404],
       [ 0.5244284 , -0.4574675 , -0.86318237,  0.24763903]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/relative_position_values/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.04105139, -0.05714124],
       [ 0.37177885, -0.1823186 ],
       [-0.23018137,  0.22389114],
       [ 0.32058078, -0.14815432],
       [-0.43768305,  0.31061643],
       [-0.02394754,  0.19637132],
       [-0.2374571 ,  0.3157737 ],
       [ 0.36619416,  0.09009252],
       [-0.40879214,  0.3197837 ],
       [ 0.02673276, -0.00661518],
       [ 0.41187954,  0.47705537],
       [ 0.45878202, -0.32024944],
       [ 0.51065665, -0.30870417],
       [-0.28584456,  0.23089117],
       [-0.35178   ,  0.3726828 ],
       [ 0.5460494 ,  0.22242838],
       [-0.39283216, -0.15411842]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_queries/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.00046835, -0.00584295, -0.00167091, -0.00098665],
       [ 0.00120321,  0.01153889, -0.00217633,  0.0029907 ],
       [-0.00119333, -0.00582787, -0.00764152,  0.00202452],
       [ 0.00045876,  0.00013055,  0.01149488, -0.00403077]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([2.5062525e-07, 8.1206799e-06, 1.2732174e-05, 1.0037031e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_output/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[1.3187597e-05, 1.2500873e-05, 1.3938123e-05, 3.4654922e-06],
       [4.2119152e-07, 2.6876501e-07, 1.1507026e-07, 1.8013898e-07],
       [6.8745743e-07, 3.4745034e-07, 5.3398293e-07, 9.2183711e-07],
       [5.0219027e-05, 2.6699347e-05, 1.1532027e-05, 9.0387393e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_output/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.01139506, -0.01195775,  0.00037938,  0.00017439],
       [-0.00209744,  0.00119319,  0.00013822,  0.00036361],
       [ 0.00143587, -0.00138437,  0.00049455, -0.0015446 ],
       [ 0.02528998, -0.01876787,  0.00051381, -0.00813957]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.01825139, -0.01425669, -0.00045046, -0.00345694], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_output/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-4.0563243e-04,  4.9347890e-04, -3.0052048e-04,  9.1323731e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[1.2888732e-06, 4.5875780e-07, 3.7605730e-07, 1.2563765e-06],
       [4.7593553e-06, 1.5592951e-06, 7.3782411e-07, 3.3539093e-06],
       [9.1067950e-06, 2.4938354e-06, 8.1068288e-07, 5.6728718e-06],
       [3.8393550e-06, 1.0206575e-06, 3.7192322e-07, 2.5701656e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[-3.6460180e-03,  1.5931845e-03,  1.0455698e-03, -9.7345845e-05],
       [ 7.2560101e-03, -3.3537981e-03, -1.3520650e-03, -1.8156531e-03],
       [-9.8453099e-03,  4.5084325e-03,  1.3002729e-03,  2.7107631e-03],
       [ 6.2382570e-03, -2.7498757e-03, -9.9531806e-04, -8.0029073e-04]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_keys/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.46596065,  0.3952483 ,  0.76063615,  0.49716362],
       [-0.6456495 ,  0.15895243, -0.2998525 ,  0.02327987],
       [-0.55998045,  0.41293883,  0.41484472, -0.5472586 ],
       [ 0.11284868, -0.4933339 ,  0.17511149, -0.14242795]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([9.8821700e-13, 6.5451171e-14, 1.4367941e-13, 3.2583192e-13],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([3.0029471e-06, 3.1407055e-07, 1.3767034e-06, 1.0828462e-07],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([5.5241999e-06, 8.0863138e-06, 3.7238933e-05, 1.7916744e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/outer/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[5.5384754e-07, 1.1365790e-05, 5.0376111e-06, 2.3296061e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/outer/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.22100142, -0.79167676, -0.10937379,  1.0830617 ]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/relative_position_keys/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [4.6874284e-08, 1.5687058e-07],
       [2.1940455e-06, 1.2239519e-07],
       [2.7130204e-06, 2.5646486e-07],
       [3.0144477e-07, 5.0058372e-07],
       [2.4839605e-07, 2.3636049e-07],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_queries/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.5970236 ,  0.6124645 ,  0.07404053,  0.423024  ],
       [-0.06645507,  0.31788856,  0.23721343, -0.25078228],
       [ 0.8364451 , -0.61345243,  0.68695724,  0.32764232],
       [-0.11762387,  0.5064825 ,  0.6422673 ,  0.37066793]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_output/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00020207,  0.00051604, -0.00050824, -0.00050613], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/outer/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([5.4658467e-06, 2.4112710e-04, 9.7791730e-05, 2.3170171e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([1.8461305e-12, 2.9259637e-12, 7.1953491e-14, 7.6359145e-13],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/outer/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00326136, -0.06955137,  0.04436373,  0.01823404], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_queries/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[1.3333246e-07, 4.9570713e-06, 1.1861255e-06, 1.2960152e-07],
       [4.3440653e-07, 1.8925433e-05, 1.2108799e-05, 1.2396783e-06],
       [2.0137422e-07, 3.1481352e-06, 4.2260144e-06, 2.8359057e-07],
       [2.0809851e-07, 1.6874170e-06, 1.7372688e-05, 1.6878322e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/outer/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-6.2635867e-05,  5.1921490e-04, -5.1552011e-04, -5.1160913e-04],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([7.2795683e-06, 4.1643730e-06, 2.4570811e-05, 6.1296469e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/inner/bias/.ATTRIBUTES/VARIABLE_VALUE
array([0.00044359], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/outer/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.00158291, -0.01002621,  0.00657476,  0.00461164]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_queries/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-1.8127909e-01, -4.1979714e-03,  5.8023065e-01,  4.9677259e-01],
       [ 8.3308876e-01, -6.8315411e-01, -2.0081217e-04, -3.6606595e-02],
       [-9.6196570e-03,  7.6596701e-01,  8.1999314e-01, -3.1343913e-01],
       [ 1.8173505e-02, -2.6273718e-01,  5.9359020e-01,  2.5351110e-01]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00452514,  0.00741799,  0.00681977, -0.00026826], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/outer/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([2.6266765e-05, 1.7316550e-05, 6.4314072e-06, 1.5871859e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/inner/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([0.01906918], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/outer/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.35281876, -0.04029938, -0.9346319 , -1.0388818 ]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([8.3728883e-06, 2.6089706e-06, 3.6723926e-05, 1.1102085e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/inner/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00032462], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/relative_position_keys/.ATTRIBUTES/VARIABLE_VALUE
array([[ 2.9330778e-01, -2.1494746e-02],
       [ 1.2982488e-03, -3.8428718e-01],
       [-7.2103292e-02, -4.5253295e-01],
       [-3.6950946e-02,  4.7471720e-01],
       [-3.2999581e-01,  4.0227371e-01],
       [-4.7675097e-01, -5.6022888e-01],
       [-2.9588029e-01,  2.1405272e-02],
       [-3.5867214e-01,  9.8343194e-03],
       [-3.7135085e-01,  4.0112352e-01],
       [ 5.1852077e-01,  7.9984546e-02],
       [-3.6570367e-01,  1.7876315e-01],
       [-1.5114087e-01, -4.4781658e-01],
       [-3.1184557e-01, -2.4099565e-01],
       [ 3.7372112e-05, -1.9337311e-01],
       [-4.9292314e-01,  1.1126840e-01],
       [ 4.7540766e-01, -3.0765858e-01],
       [-2.7819136e-01, -3.6287856e-01]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/input_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE
array([0.9999568, 1.0002735, 0.9997584, 1.0000601], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [-8.3422216e-05,  2.5232066e-03],
       [ 3.7883739e-03,  1.2375599e-03],
       [ 3.3930242e-03,  3.1925230e-03],
       [ 2.1911284e-03,  3.2794354e-03],
       [ 1.3486779e-03,  2.8771469e-03],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00],
       [ 0.0000000e+00,  0.0000000e+00]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([6.1679981e-05, 1.7789079e-04, 1.3891949e-04, 1.2741468e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([5.463848e-06, 1.717469e-04, 8.404793e-05, 1.562335e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[4.3702785e-06, 2.1504959e-05, 1.2551620e-06, 7.8652811e-06],
       [3.0421018e-06, 4.1775402e-05, 1.0617806e-06, 2.1829635e-05],
       [1.4484329e-05, 1.4440057e-05, 2.5346624e-06, 5.9425900e-05],
       [2.4404544e-05, 4.1539315e-05, 3.2862049e-06, 3.1374271e-05]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_keys/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.64822567, -0.812534  ,  0.44917238,  0.36562005],
       [ 0.61204755,  0.6335715 ,  0.8384981 , -0.5899898 ],
       [-0.07566014, -0.1723189 , -0.5864283 ,  0.5284123 ],
       [ 0.8329904 ,  0.02374487, -0.56980926,  0.48205793]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00618606, -0.00254871,  0.00881142, -0.01977676], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/examples_inputter/labels_inputter/embedding/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.03129838, -0.05005769, -0.006254  ,  0.02411106],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.00695551,  0.02633511, -0.00848422, -0.01669259],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.03361873, -0.08123093,  0.06043056,  0.05707579],
       [ 0.00495319, -0.01118624,  0.00068403,  0.00090333],
       [-0.00093235, -0.00039261,  0.00113684,  0.00043871],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.02911119,  0.00698393, -0.00887501,  0.0067525 ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.00624827, -0.00173503, -0.00508258,  0.01707061]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.03074773, -0.01270913, -0.02256053, -0.00910793], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-9.6171127e-05, -5.9377337e-03,  6.9456380e-03, -3.1705978e-03],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
_CHECKPOINTABLE_OBJECT_GRAPH
(b'\n0\n\t\x08\x01\x12\x05model\n\r\x08\x02\x12\toptimizer\n\x10\x08\x03'
 b'\x12\x0csave_counter*\x02\x08\x01\nA\n\x15\x08\x04\x12\x11examples_input'
 b'ter\n\n\x08\x05\x12\x06params\n\x0b\x08\x06\x12\x07encoder\n\x0b\x08\x07'
 b'\x12\x07decoder*\x02\x08\x01\n\xef\x08\n\x08\x08\x08\x12\x04iter\n\n'
 b'\x08\t\x12\x06beta_1\n\n\x08\n\x12\x06beta_2\n\t\x08\x0b\x12\x05deca'
 b'y\x1a\x08\x08\x1a\x12\x01m\x18\x83\x01\x1a\x08\x08\x1d\x12\x01m\x18\x84'
 b'\x01\x1a\x08\x08\x1f\x12\x01m\x18\x85\x01\x1a\x08\x08 \x12\x01m\x18\x86'
 b'\x01\x1a\x08\x08#\x12\x01m\x18\x87\x01\x1a\x08\x08$\x12\x01m\x18\x88'
 b"\x01\x1a\x08\x08&\x12\x01m\x18\x89\x01\x1a\x08\x08'\x12\x01m\x18\x8a"
 b'\x01\x1a\x08\x08B\x12\x01m\x18\x8b\x01\x1a\x08\x08C\x12\x01m\x18\x8c'
 b'\x01\x1a\x08\x08E\x12\x01m\x18\x8d\x01\x1a\x08\x08F\x12\x01m\x18\x8e'
 b'\x01\x1a\x08\x08J\x12\x01m\x18\x8f\x01\x1a\x08\x08K\x12\x01m\x18\x90'
 b'\x01\x1a\x08\x08P\x12\x01m\x18\x91\x01\x1a\x08\x08Q\x12\x01m\x18\x92'
 b'\x01\x1a\x08\x08S\x12\x01m\x18\x93\x01\x1a\x08\x08T\x12\x01m\x18\x94'
 b'\x01\x1a\x08\x08Z\x12\x01m\x18\x95\x01\x1a\x08\x08[\x12\x01m\x18\x96'
 b'\x01\x1a\x08\x08\\\x12\x01m\x18\x97\x01\x1a\x08\x08]\x12\x01m\x18\x98'
 b'\x01\x1a\x08\x08^\x12\x01m\x18\x99\x01\x1a\x08\x08_\x12\x01m\x18\x9a'
 b'\x01\x1a\x08\x08`\x12\x01m\x18\x9b\x01\x1a\x08\x08a\x12\x01m\x18\x9c'
 b'\x01\x1a\x08\x08b\x12\x01m\x18\x9d\x01\x1a\x08\x08c\x12\x01m\x18\x9e'
 b'\x01\x1a\x08\x08d\x12\x01m\x18\x9f\x01\x1a\x08\x08e\x12\x01m\x18\xa0'
 b'\x01\x1a\x08\x08f\x12\x01m\x18\xa1\x01\x1a\x08\x08g\x12\x01m\x18\xa2'
 b'\x01\x1a\x08\x08h\x12\x01m\x18\xa3\x01\x1a\x08\x08i\x12\x01m\x18\xa4'
 b'\x01\x1a\x08\x08j\x12\x01m\x18\xa5\x01\x1a\x08\x08k\x12\x01m\x18\xa6'
 b'\x01\x1a\x08\x08l\x12\x01m\x18\xa7\x01\x1a\x08\x08m\x12\x01m\x18\xa8'
 b'\x01\x1a\x08\x08n\x12\x01m\x18\xa9\x01\x1a\x08\x08o\x12\x01m\x18\xaa'
 b'\x01\x1a\x08\x08u\x12\x01m\x18\xab\x01\x1a\x08\x08v\x12\x01m\x18\xac'
 b'\x01\x1a\x08\x08w\x12\x01m\x18\xad\x01\x1a\x08\x08x\x12\x01m\x18\xae'
 b'\x01\x1a\x08\x08y\x12\x01m\x18\xaf\x01\x1a\x08\x08z\x12\x01m\x18\xb0'
 b'\x01\x1a\x08\x08{\x12\x01m\x18\xb1\x01\x1a\x08\x08|\x12\x01m\x18\xb2'
 b'\x01\x1a\x08\x08}\x12\x01m\x18\xb3\x01\x1a\x08\x08~\x12\x01m\x18\xb4'
 b'\x01\x1a\x08\x08\x7f\x12\x01m\x18\xb5\x01\x1a\t\x08\x80\x01\x12\x01m\x18'
 b'\xb6\x01\x1a\t\x08\x81\x01\x12\x01m\x18\xb7\x01\x1a\t\x08\x82\x01\x12\x01'
 b'm\x18\xb8\x01\x1a\x08\x08\x1a\x12\x01v\x18\xb9\x01\x1a\x08\x08\x1d\x12\x01'
 b'v\x18\xba\x01\x1a\x08\x08\x1f\x12\x01v\x18\xbb\x01\x1a\x08\x08 \x12\x01'
 b'v\x18\xbc\x01\x1a\x08\x08#\x12\x01v\x18\xbd\x01\x1a\x08\x08$\x12\x01'
 b"v\x18\xbe\x01\x1a\x08\x08&\x12\x01v\x18\xbf\x01\x1a\x08\x08'\x12\x01"
 b'v\x18\xc0\x01\x1a\x08\x08B\x12\x01v\x18\xc1\x01\x1a\x08\x08C\x12\x01'
 b'v\x18\xc2\x01\x1a\x08\x08E\x12\x01v\x18\xc3\x01\x1a\x08\x08F\x12\x01'
 b'v\x18\xc4\x01\x1a\x08\x08J\x12\x01v\x18\xc5\x01\x1a\x08\x08K\x12\x01'
 b'v\x18\xc6\x01\x1a\x08\x08P\x12\x01v\x18\xc7\x01\x1a\x08\x08Q\x12\x01'
 b'v\x18\xc8\x01\x1a\x08\x08S\x12\x01v\x18\xc9\x01\x1a\x08\x08T\x12\x01'
 b'v\x18\xca\x01\x1a\x08\x08Z\x12\x01v\x18\xcb\x01\x1a\x08\x08[\x12\x01'
 b'v\x18\xcc\x01\x1a\x08\x08\\\x12\x01v\x18\xcd\x01\x1a\x08\x08]\x12\x01'
 b'v\x18\xce\x01\x1a\x08\x08^\x12\x01v\x18\xcf\x01\x1a\x08\x08_\x12\x01'
 b'v\x18\xd0\x01\x1a\x08\x08`\x12\x01v\x18\xd1\x01\x1a\x08\x08a\x12\x01'
 b'v\x18\xd2\x01\x1a\x08\x08b\x12\x01v\x18\xd3\x01\x1a\x08\x08c\x12\x01'
 b'v\x18\xd4\x01\x1a\x08\x08d\x12\x01v\x18\xd5\x01\x1a\x08\x08e\x12\x01'
 b'v\x18\xd6\x01\x1a\x08\x08f\x12\x01v\x18\xd7\x01\x1a\x08\x08g\x12\x01'
 b'v\x18\xd8\x01\x1a\x08\x08h\x12\x01v\x18\xd9\x01\x1a\x08\x08i\x12\x01'
 b'v\x18\xda\x01\x1a\x08\x08j\x12\x01v\x18\xdb\x01\x1a\x08\x08k\x12\x01'
 b'v\x18\xdc\x01\x1a\x08\x08l\x12\x01v\x18\xdd\x01\x1a\x08\x08m\x12\x01'
 b'v\x18\xde\x01\x1a\x08\x08n\x12\x01v\x18\xdf\x01\x1a\x08\x08o\x12\x01'
 b'v\x18\xe0\x01\x1a\x08\x08u\x12\x01v\x18\xe1\x01\x1a\x08\x08v\x12\x01'
 b'v\x18\xe2\x01\x1a\x08\x08w\x12\x01v\x18\xe3\x01\x1a\x08\x08x\x12\x01'
 b'v\x18\xe4\x01\x1a\x08\x08y\x12\x01v\x18\xe5\x01\x1a\x08\x08z\x12\x01'
 b'v\x18\xe6\x01\x1a\x08\x08{\x12\x01v\x18\xe7\x01\x1a\x08\x08|\x12\x01'
 b'v\x18\xe8\x01\x1a\x08\x08}\x12\x01v\x18\xe9\x01\x1a\x08\x08~\x12\x01'
 b'v\x18\xea\x01\x1a\x08\x08\x7f\x12\x01v\x18\xeb\x01\x1a\t\x08\x80\x01\x12'
 b'\x01v\x18\xec\x01\x1a\t\x08\x81\x01\x12\x01v\x18\xed\x01\x1a\t\x08\x82'
 b'\x01\x12\x01v\x18\xee\x01*\x02\x08\x01\nM\x12G\n\x0eVARIABLE_VALUE\x12'
 b"\x0csave_counter\x1a'save_counter/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\no"
 b'\n\x15\x08\x0c\x12\x11features_inputter\n\x13\x08\r\x12\x0flabels_inputter'
 b'\n\r\x08\x0e\x12\tinputters\n\x18\x08\x0f\x12\x14accepted_annotation'
 b's\n\x14\x08\x10\x12\x10annotation_files*\x02\x08\x01\n*\n\x14\x08'
 b'\x11\x12\x10optimizer_params\n\x10\x08\x12\x12\x0cdecay_params*\x00\n'
 b' \n\x0e\x08\x13\x12\nlayer_norm\n\n\x08\x14\x12\x06layers*\x02\x08\x01\n2\n'
 b'\x0e\x08\x15\x12\nlayer_norm\n\n\x08\x16\x12\x06layers\n\x10\x08\x17\x12'
 b'\x0coutput_layer*\x02\x08\x01\nG\x12A\n\x0eVARIABLE_VALUE\x12\x04iter\x1a'
 b')optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\nK\x12E\n\x0eVARI'
 b'ABLE_VALUE\x12\x06beta_1\x1a+optimizer/beta_1/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\nK\x12E\n\x0eVARIABLE_VALUE\x12\x06beta_2\x1a+optimizer/beta_'
 b'2/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\nI\x12C\n\x0eVARIABLE_VALUE'
 b'\x12\x05decay\x1a*optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'9\n\x11\x08\x18\x12\rtokens_to_ids\n\x11\x08\x19\x12\rids_to_tokens\n'
 b'\r\x08\x1a\x12\tembedding*\x02\x08\x01\n9\n\x11\x08\x1b\x12\rtokens_to_ids\n'
 b'\x11\x08\x1c\x12\rids_to_tokens\n\r\x08\x1d\x12\tembedding*\x02\x08'
 b'\x01\n\x12\n\x05\x08\x0c\x12\x010\n\x05\x08\r\x12\x011*\x02\x08\x01\n\x02*'
 b'\x00\n\x02*\x00\n\x02*\x00\n\x02*\x00\n#\n\x08\x08\x1e\x12\x04axis\n\t\x08'
 b'\x1f\x12\x05gamma\n\x08\x08 \x12\x04beta*\x02\x08\x01\n\x0b\n\x05\x08!'
 b'\x12\x010*\x02\x08\x01\n#\n\x08\x08"\x12\x04axis\n\t\x08#\x12\x05gamma\n\x08'
 b'\x08$\x12\x04beta*\x02\x08\x01\n\x0b\n\x05\x08%\x12\x010*\x02\x08'
 b"\x01\n\x1a\n\n\x08&\x12\x06kernel\n\x08\x08'\x12\x04bias*\x02\x08"
 b'\x01\n\x14\n\x10\x08(\x12\x0c_initializer*\x00\n\x14\n\x10\x08)\x12\x0c_init'
 b'ializer*\x00\n\x80\x01\x12z\n\x0eVARIABLE_VALUE\x12\x18custom_model_2/embed'
 b'ding\x1aNmodel/examples_inputter/features_inputter/embedding/.ATTRIBUTES/VA'
 b'RIABLE_VALUE*\x02\x08\x01\n\x14\n\x10\x08*\x12\x0c_initializer*\x00\n\x14'
 b'\n\x10\x08+\x12\x0c_initializer*\x00\n~\x12x\n\x0eVARIABLE_VALUE\x12\x18cu'
 b'stom_model_2/embedding\x1aLmodel/examples_inputter/labels_inputter/embeddin'
 b'g/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x02*\x00\n\x8f\x01\x12'
 b'\x88\x01\n\x0eVARIABLE_VALUE\x12;custom_model_2/self_attention_encoder_2/'
 b'layer_norm_14/gamma\x1a9model/encoder/layer_norm/gamma/.ATTRIBUTES/VARIABLE'
 b'_VALUE*\x02\x08\x01\n\x8d\x01\x12\x86\x01\n\x0eVARIABLE_VALUE\x12:custom_mod'
 b'el_2/self_attention_encoder_2/layer_norm_14/beta\x1a8model/encoder/layer_no'
 b'rm/beta/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n!\n\x12\x08,\x12\x0eself_a'
 b'ttention\n\x07\x08-\x12\x03ffn*\x02\x08\x01\n\x02*\x00\n\x8f\x01'
 b'\x12\x88\x01\n\x0eVARIABLE_VALUE\x12;custom_model_2/self_attention_decoder_2'
 b'/layer_norm_17/gamma\x1a9model/decoder/layer_norm/gamma/.ATTRIBUTES/VARIABL'
 b'E_VALUE*\x02\x08\x01\n\x8d\x01\x12\x86\x01\n\x0eVARIABLE_VALUE\x12:custom_mo'
 b'del_2/self_attention_decoder_2/layer_norm_17/beta\x1a8model/decoder/layer_n'
 b'orm/beta/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n0\n\x12\x08.\x12\x0eself_'
 b'attention\n\r\x08/\x12\tattention\n\x07\x080\x12\x03ffn*\x02\x08'
 b'\x01\n\x8e\x01\x12\x87\x01\n\x0eVARIABLE_VALUE\x127custom_model_2/self_att'
 b'ention_decoder_2/dense_49/kernel\x1a<model/decoder/output_layer/kernel/.ATT'
 b'RIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x8a\x01\x12\x83\x01\n\x0eVARIABLE_V'
 b'ALUE\x125custom_model_2/self_attention_decoder_2/dense_49/bias\x1a:model/d'
 b'ecoder/output_layer/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\x11\n\r\x081\x12\t_filename*\x00\n\x11\n\r\x082\x12\t_filename*\x00\n\x11\n'
 b'\r\x083\x12\t_filename*\x00\n\x11\n\r\x084\x12\t_filename*\x00\n%\n\t\x08'
 b'5\x12\x05layer\n\x14\x086\x12\x10input_layer_norm*\x02\x08\x01\n%\n\t\x087'
 b'\x12\x05layer\n\x14\x088\x12\x10input_layer_norm*\x02\x08\x01\n%\n'
 b'\t\x089\x12\x05layer\n\x14\x08:\x12\x10input_layer_norm*\x02\x08\x01'
 b'\n\x0b\n\x05\x08;\x12\x010*\x02\x08\x01\n%\n\t\x08<\x12\x05layer\n\x14'
 b'\x08=\x12\x10input_layer_norm*\x02\x08\x01\n\x02*\x00\n\x02*\x00\n\x02*\x00'
 b'\n\x02*\x00\n\x89\x01\n\x12\x08>\x12\x0elinear_queries\n\x0f\x08?\x12\x0blin'
 b'ear_keys\n\x11\x08@\x12\rlinear_values\n\x11\x08A\x12\rlinear_output\n\x1a'
 b'\x08B\x12\x16relative_position_keys\n\x1c\x08C\x12\x18relative_position_va'
 b'lues*\x02\x08\x01\n#\n\x08\x08D\x12\x04axis\n\t\x08E\x12\x05gamma\n'
 b'\x08\x08F\x12\x04beta*\x02\x08\x01\n\x1a\n\t\x08G\x12\x05inner\n\t'
 b'\x08H\x12\x05outer*\x02\x08\x01\n#\n\x08\x08I\x12\x04axis\n\t\x08J\x12\x05g'
 b'amma\n\x08\x08K\x12\x04beta*\x02\x08\x01\n\x89\x01\n\x12\x08L\x12\x0elinea'
 b'r_queries\n\x0f\x08M\x12\x0blinear_keys\n\x11\x08N\x12\rlinear_value'
 b's\n\x11\x08O\x12\rlinear_output\n\x1a\x08P\x12\x16relative_position_keys'
 b'\n\x1c\x08Q\x12\x18relative_position_values*\x02\x08\x01\n#\n\x08\x08R'
 b'\x12\x04axis\n\t\x08S\x12\x05gamma\n\x08\x08T\x12\x04beta*\x02\x08\x01\n'
 b'%\n\t\x08U\x12\x05layer\n\x14\x08V\x12\x10input_layer_norm*\x02'
 b'\x08\x01\n\x1a\n\t\x08W\x12\x05inner\n\t\x08X\x12\x05outer*\x02\x08\x01\n#'
 b'\n\x08\x08Y\x12\x04axis\n\t\x08Z\x12\x05gamma\n\x08\x08[\x12\x04beta*'
 b'\x02\x08\x01\n\x1a\n\n\x08\\\x12\x06kernel\n\x08\x08]\x12\x04bias*'
 b'\x02\x08\x01\n\x1a\n\n\x08^\x12\x06kernel\n\x08\x08_\x12\x04bias*'
 b'\x02\x08\x01\n\x1a\n\n\x08`\x12\x06kernel\n\x08\x08a\x12\x04bias*'
 b'\x02\x08\x01\n\x1a\n\n\x08b\x12\x06kernel\n\x08\x08c\x12\x04bias*'
 b'\x02\x08\x01\n\x8a\x02\x12\x83\x02\n\x0eVARIABLE_VALUE\x12\x91\x01custom_m'
 b'odel_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_l'
 b'ayer_wrapper_10/multi_head_attention_6/relative_position_keys\x1a]model/enc'
 b'oder/layers/0/self_attention/layer/relative_position_keys/.ATTRIBUTES/VARIAB'
 b'LE_VALUE*\x02\x08\x01\n\x8e\x02\x12\x87\x02\n\x0eVARIABLE_VALUE\x12\x93'
 b'\x01custom_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/'
 b'transformer_layer_wrapper_10/multi_head_attention_6/relative_position_values'
 b'\x1a_model/encoder/layers/0/self_attention/layer/relative_position_values/.'
 b'ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x02*\x00\n\xe9\x01\x12\xe2\x01\n'
 b'\x0eVARIABLE_VALUE\x12wcustom_model_2/self_attention_encoder_2/self_attent'
 b'ion_encoder_layer_2/transformer_layer_wrapper_10/layer_norm_15/gamma\x1aWmo'
 b'del/encoder/layers/0/self_attention/input_layer_norm/gamma/.ATTRIBUTES/VARIA'
 b'BLE_VALUE*\x02\x08\x01\n\xe7\x01\x12\xe0\x01\n\x0eVARIABLE_VALUE\x12vcustom_'
 b'model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_'
 b'layer_wrapper_10/layer_norm_15/beta\x1aVmodel/encoder/layers/0/self_attenti'
 b'on/input_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\x1a\n\n\x08d\x12\x06kernel\n\x08\x08e\x12\x04bias*\x02\x08\x01\n'
 b'\x1a\n\n\x08f\x12\x06kernel\n\x08\x08g\x12\x04bias*\x02\x08\x01\n\x02*\x00\n'
 b'\xde\x01\x12\xd7\x01\n\x0eVARIABLE_VALUE\x12wcustom_model_2/self_attention'
 b'_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/layer'
 b'_norm_16/gamma\x1aLmodel/encoder/layers/0/ffn/input_layer_norm/gamma/.ATTRI'
 b'BUTES/VARIABLE_VALUE*\x02\x08\x01\n\xdc\x01\x12\xd5\x01\n\x0eVARIABLE_VAL'
 b'UE\x12vcustom_model_2/self_attention_encoder_2/self_attention_encoder_layer'
 b'_2/transformer_layer_wrapper_11/layer_norm_16/beta\x1aKmodel/encoder/layers'
 b'/0/ffn/input_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\x1a\n\n\x08h\x12\x06kernel\n\x08\x08i\x12\x04bias*\x02\x08\x01\n'
 b'\x1a\n\n\x08j\x12\x06kernel\n\x08\x08k\x12\x04bias*\x02\x08\x01\n'
 b'\x1a\n\n\x08l\x12\x06kernel\n\x08\x08m\x12\x04bias*\x02\x08\x01\n'
 b'\x1a\n\n\x08n\x12\x06kernel\n\x08\x08o\x12\x04bias*\x02\x08\x01\n'
 b'\x8a\x02\x12\x83\x02\n\x0eVARIABLE_VALUE\x12\x91\x01custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/'
 b'multi_head_attention_7/relative_position_keys\x1a]model/decoder/layers/0/se'
 b'lf_attention/layer/relative_position_keys/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x8e\x02\x12\x87\x02\n\x0eVARIABLE_VALUE\x12\x93\x01custom_'
 b'model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_'
 b'layer_wrapper_12/multi_head_attention_7/relative_position_values\x1a_model/'
 b'decoder/layers/0/self_attention/layer/relative_position_values/.ATTRIBUTES/V'
 b'ARIABLE_VALUE*\x02\x08\x01\n\x02*\x00\n\xe9\x01\x12\xe2\x01\n\x0eVARIABLE_VA'
 b'LUE\x12wcustom_model_2/self_attention_decoder_2/self_attention_decoder_laye'
 b'r_2/transformer_layer_wrapper_12/layer_norm_18/gamma\x1aWmodel/decoder/laye'
 b'rs/0/self_attention/input_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\xe7\x01\x12\xe0\x01\n\x0eVARIABLE_VALUE\x12vcustom_model_2/'
 b'self_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wr'
 b'apper_12/layer_norm_18/beta\x1aVmodel/decoder/layers/0/self_attention/input'
 b'_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\nO\n\x12\x08'
 b'p\x12\x0elinear_queries\n\x0f\x08q\x12\x0blinear_keys\n\x11\x08r\x12\rline'
 b'ar_values\n\x11\x08s\x12\rlinear_output*\x02\x08\x01\n#\n\x08\x08t\x12\x04'
 b'axis\n\t\x08u\x12\x05gamma\n\x08\x08v\x12\x04beta*\x02\x08\x01\n\x1a\n'
 b'\n\x08w\x12\x06kernel\n\x08\x08x\x12\x04bias*\x02\x08\x01\n\x1a\n\n\x08y\x12'
 b'\x06kernel\n\x08\x08z\x12\x04bias*\x02\x08\x01\n\x02*\x00\n\xde\x01'
 b'\x12\xd7\x01\n\x0eVARIABLE_VALUE\x12wcustom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_14/layer_norm_20/g'
 b'amma\x1aLmodel/decoder/layers/0/ffn/input_layer_norm/gamma/.ATTRIBUTES/VARI'
 b'ABLE_VALUE*\x02\x08\x01\n\xdc\x01\x12\xd5\x01\n\x0eVARIABLE_VALUE\x12vcustom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_14/layer_norm_20/beta\x1aKmodel/decoder/layers/0/ffn/input_l'
 b'ayer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x82\x02'
 b'\x12\xfb\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self_attention_'
 b'encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_'
 b'head_attention_6/dense_33/kernel\x1a\\model/encoder/layers/0/self_attention/'
 b'layer/linear_queries/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xfe'
 b'\x01\x12\xf7\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_atten'
 b'tion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/m'
 b'ulti_head_attention_6/dense_33/bias\x1aZmodel/encoder/layers/0/self_attenti'
 b'on/layer/linear_queries/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xff\x01\x12\xf8\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self_atte'
 b'ntion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/'
 b'multi_head_attention_6/dense_34/kernel\x1aYmodel/encoder/layers/0/self_atte'
 b'ntion/layer/linear_keys/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08'
 b'\x01\n\xfb\x01\x12\xf4\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/sel'
 b'f_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapp'
 b'er_10/multi_head_attention_6/dense_34/bias\x1aWmodel/encoder/layers/0/self_'
 b'attention/layer/linear_keys/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\x81\x02\x12\xfa\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self_atte'
 b'ntion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/'
 b'multi_head_attention_6/dense_35/kernel\x1a[model/encoder/layers/0/self_atte'
 b'ntion/layer/linear_values/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xfd\x01\x12\xf6\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_atte'
 b'ntion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/'
 b'multi_head_attention_6/dense_35/bias\x1aYmodel/encoder/layers/0/self_attent'
 b'ion/layer/linear_values/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\x81\x02\x12\xfa\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self_atte'
 b'ntion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/'
 b'multi_head_attention_6/dense_36/kernel\x1a[model/encoder/layers/0/self_atte'
 b'ntion/layer/linear_output/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xfd\x01\x12\xf6\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_atte'
 b'ntion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/'
 b'multi_head_attention_6/dense_36/bias\x1aYmodel/encoder/layers/0/self_attent'
 b'ion/layer/linear_output/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xee\x01\x12\xe7\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self_atte'
 b'ntion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/'
 b'feed_forward_network_4/dense_37/kernel\x1aHmodel/encoder/layers/0/ffn/layer'
 b'/inner/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xea\x01\x12'
 b'\xe3\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_attention_encod'
 b'er_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/feed_forwar'
 b'd_network_4/dense_37/bias\x1aFmodel/encoder/layers/0/ffn/layer/inner/bias/.'
 b'ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xee\x01\x12\xe7\x01\n\x0eVARIABL'
 b'E_VALUE\x12\x8a\x01custom_model_2/self_attention_encoder_2/self_attention'
 b'_encoder_layer_2/transformer_layer_wrapper_11/feed_forward_network_4/dense_3'
 b'8/kernel\x1aHmodel/encoder/layers/0/ffn/layer/outer/kernel/.ATTRIBUTES/VARI'
 b'ABLE_VALUE*\x02\x08\x01\n\xea\x01\x12\xe3\x01\n\x0eVARIABLE_VALUE'
 b'\x12\x88\x01custom_model_2/self_attention_encoder_2/self_attention_encode'
 b'r_layer_2/transformer_layer_wrapper_11/feed_forward_network_4/dense_38/b'
 b'ias\x1aFmodel/encoder/layers/0/ffn/layer/outer/bias/.ATTRIBUTES/VARIABLE_VA'
 b'LUE*\x02\x08\x01\n\x82\x02\x12\xfb\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01cust'
 b'om_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transform'
 b'er_layer_wrapper_12/multi_head_attention_7/dense_39/kernel\x1a\\model/decode'
 b'r/layers/0/self_attention/layer/linear_queries/kernel/.ATTRIBUTES/VARIABLE_V'
 b'ALUE*\x02\x08\x01\n\xfe\x01\x12\xf7\x01\n\x0eVARIABLE_VALUE\x12\x88\x01cus'
 b'tom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transfor'
 b'mer_layer_wrapper_12/multi_head_attention_7/dense_39/bias\x1aZmodel/decoder'
 b'/layers/0/self_attention/layer/linear_queries/bias/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\xff\x01\x12\xf8\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_12/multi_head_attention_7/dense_40/kernel\x1aYmodel/decoder/'
 b'layers/0/self_attention/layer/linear_keys/kernel/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\n\xfb\x01\x12\xf4\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_m'
 b'odel_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_l'
 b'ayer_wrapper_12/multi_head_attention_7/dense_40/bias\x1aWmodel/decoder/laye'
 b'rs/0/self_attention/layer/linear_keys/bias/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\x81\x02\x12\xfa\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_12/multi_head_attention_7/dense_41/kernel\x1a[model/decoder/'
 b'layers/0/self_attention/layer/linear_values/kernel/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\xfd\x01\x12\xf6\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_12/multi_head_attention_7/dense_41/bias\x1aYmodel/decoder/la'
 b'yers/0/self_attention/layer/linear_values/bias/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\x81\x02\x12\xfa\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_12/multi_head_attention_7/dense_42/kernel\x1a[model/decoder/'
 b'layers/0/self_attention/layer/linear_output/kernel/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\xfd\x01\x12\xf6\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_12/multi_head_attention_7/dense_42/bias\x1aYmodel/decoder/la'
 b'yers/0/self_attention/layer/linear_output/bias/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\x1a\n\n\x08{\x12\x06kernel\n\x08\x08|\x12\x04bias*\x02\x08'
 b'\x01\n\x1a\n\n\x08}\x12\x06kernel\n\x08\x08~\x12\x04bias*\x02\x08'
 b'\x01\n\x1b\n\n\x08\x7f\x12\x06kernel\n\t\x08\x80\x01\x12\x04bias*\x02'
 b'\x08\x01\n\x1c\n\x0b\x08\x81\x01\x12\x06kernel\n\t\x08\x82\x01\x12\x04bias'
 b'*\x02\x08\x01\n\x02*\x00\n\xe6\x01\x12\xdf\x01\n\x0eVARIABLE_VALUE\x12wcust'
 b'om_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transform'
 b'er_layer_wrapper_13/layer_norm_19/gamma\x1aTmodel/decoder/layers/0/attentio'
 b'n/0/input_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xe4\x01'
 b'\x12\xdd\x01\n\x0eVARIABLE_VALUE\x12vcustom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_13/layer_norm_19/b'
 b'eta\x1aSmodel/decoder/layers/0/attention/0/input_layer_norm/beta/.ATTRIBUTE'
 b'S/VARIABLE_VALUE*\x02\x08\x01\n\xee\x01\x12\xe7\x01\n\x0eVARIABLE_VAL'
 b'UE\x12\x8a\x01custom_model_2/self_attention_decoder_2/self_attention_deco'
 b'der_layer_2/transformer_layer_wrapper_14/feed_forward_network_5/dense_47/ker'
 b'nel\x1aHmodel/decoder/layers/0/ffn/layer/inner/kernel/.ATTRIBUTES/VARIABLE_'
 b'VALUE*\x02\x08\x01\n\xea\x01\x12\xe3\x01\n\x0eVARIABLE_VALUE\x12\x88\x01cu'
 b'stom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transfo'
 b'rmer_layer_wrapper_14/feed_forward_network_5/dense_47/bias\x1aFmodel/decode'
 b'r/layers/0/ffn/layer/inner/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\xee\x01\x12\xe7\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_'
 b'2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_'
 b'wrapper_14/feed_forward_network_5/dense_48/kernel\x1aHmodel/decoder/layers/'
 b'0/ffn/layer/outer/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xea\x01\x12\xe3\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/'
 b'feed_forward_network_5/dense_48/bias\x1aFmodel/decoder/layers/0/ffn/layer/o'
 b'uter/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xff\x01\x12'
 b'\xf8\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/multi_head_'
 b'attention_8/dense_43/kernel\x1aYmodel/decoder/layers/0/attention/0/layer/li'
 b'near_queries/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xfb'
 b'\x01\x12\xf4\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_atten'
 b'tion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/m'
 b'ulti_head_attention_8/dense_43/bias\x1aWmodel/decoder/layers/0/attention/0/'
 b'layer/linear_queries/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xfc\x01\x12\xf5\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_13/multi_head_attention_8/dense_44/kernel\x1aVmodel/decoder/layers/0/atte'
 b'ntion/0/layer/linear_keys/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xf8\x01\x12\xf1\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/'
 b'multi_head_attention_8/dense_44/bias\x1aTmodel/decoder/layers/0/attention/0'
 b'/layer/linear_keys/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xfe'
 b'\x01\x12\xf7\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self_atten'
 b'tion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/m'
 b'ulti_head_attention_8/dense_45/kernel\x1aXmodel/decoder/layers/0/attention/'
 b'0/layer/linear_values/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xfa\x01\x12\xf3\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/'
 b'multi_head_attention_8/dense_45/bias\x1aVmodel/decoder/layers/0/attention/0'
 b'/layer/linear_values/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xfe\x01\x12\xf7\x01\n\x0eVARIABLE_VALUE\x12\x8a\x01custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_13/multi_head_attention_8/dense_46/kernel\x1aXmodel/decoder/layers/0/atte'
 b'ntion/0/layer/linear_output/kernel/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08'
 b'\x01\n\xfa\x01\x12\xf3\x01\n\x0eVARIABLE_VALUE\x12\x88\x01custom_model_2/sel'
 b'f_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapp'
 b'er_13/multi_head_attention_8/dense_46/bias\x1aVmodel/decoder/layers/0/atten'
 b'tion/0/layer/linear_output/bias/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\xae\x01\x12\xa7\x01\n\x0eVARIABLE_VALUE\x12)custom_model_2/cus'
 b'tom_model_2/embedding/m\x1ajmodel/examples_inputter/features_inputter/embed'
 b'ding/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xac\x01\x12\xa5\x01\n\x0eVARIABLE_VALUE\x12)custom_model_2/custom_model_2'
 b'/embedding/m\x1ahmodel/examples_inputter/labels_inputter/embedding/.OPTIMIZ'
 b'ER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xe3'
 b'\x01\x12\xdc\x01\n\x0eVARIABLE_VALUE\x12scustom_model_2/self_attention_enco'
 b'der_2/layer_norm_14/custom_model_2/self_attention_encoder_2/layer_norm_14/ga'
 b'mma/m\x1aUmodel/encoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRI'
 b'BUTES/VARIABLE_VALUE*\x02\x08\x01\n\xe1\x01\x12\xda\x01\n\x0eVARIABLE_VAL'
 b'UE\x12rcustom_model_2/self_attention_encoder_2/layer_norm_14/custom_model_2'
 b'/self_attention_encoder_2/layer_norm_14/beta/m\x1aTmodel/encoder/layer_norm'
 b'/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xe3\x01\x12\xdc\x01\n\x0eVARIABLE_VALUE\x12scustom_model_2/self_attentio'
 b'n_decoder_2/layer_norm_17/custom_model_2/self_attention_decoder_2/layer_norm'
 b'_17/gamma/m\x1aUmodel/decoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/'
 b'.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xe1\x01\x12\xda\x01\n\x0eVARIAB'
 b'LE_VALUE\x12rcustom_model_2/self_attention_decoder_2/layer_norm_17/custom_m'
 b'odel_2/self_attention_decoder_2/layer_norm_17/beta/m\x1aTmodel/decoder/laye'
 b'r_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\xdd\x01\x12\xd6\x01\n\x0eVARIABLE_VALUE\x12jcustom_model_2/sel'
 b'f_attention_decoder_2/dense_49/custom_model_2/self_attention_decoder_2/dense'
 b'_49/kernel/m\x1aXmodel/decoder/output_layer/kernel/.OPTIMIZER_SLOT/optimize'
 b'r/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xd9\x01\x12\xd2\x01\n\x0eVA'
 b'RIABLE_VALUE\x12hcustom_model_2/self_attention_decoder_2/dense_49/custom_mo'
 b'del_2/self_attention_decoder_2/dense_49/bias/m\x1aVmodel/decoder/output_lay'
 b'er/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_'
 b'2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_'
 b'wrapper_10/multi_head_attention_6/custom_model_2/self_attention_encoder_2/se'
 b'lf_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attenti'
 b'on_6/relative_position_keys/m\x1aymodel/encoder/layers/0/self_attention/lay'
 b'er/relative_position_keys/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_V'
 b'ALUE*\x02\x08\x01\n\xa7\x03\x12\xa0\x03\n\x0eVARIABLE_VALUE\x12\x90\x02cus'
 b'tom_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transfor'
 b'mer_layer_wrapper_10/multi_head_attention_6/custom_model_2/self_attention_en'
 b'coder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_he'
 b'ad_attention_6/relative_position_values/m\x1a{model/encoder/layers/0/self_a'
 b'ttention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBU'
 b'TES/VARIABLE_VALUE*\x02\x08\x01\n\xfa\x02\x12\xf3\x02\n\x0eVARIABLE_VALUE'
 b'\x12\xeb\x01custom_model_2/self_attention_encoder_2/self_attention_encode'
 b'r_layer_2/transformer_layer_wrapper_10/layer_norm_15/custom_model_2/self_att'
 b'ention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10'
 b'/layer_norm_15/gamma/m\x1asmodel/encoder/layers/0/self_attention/input_laye'
 b'r_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\n\xf8\x02\x12\xf1\x02\n\x0eVARIABLE_VALUE\x12\xea\x01custom_m'
 b'odel_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_l'
 b'ayer_wrapper_10/layer_norm_15/custom_model_2/self_attention_encoder_2/self_a'
 b'ttention_encoder_layer_2/transformer_layer_wrapper_10/layer_norm_15/beta'
 b'/m\x1armodel/encoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZ'
 b'ER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xef'
 b'\x02\x12\xe8\x02\n\x0eVARIABLE_VALUE\x12\xeb\x01custom_model_2/self_atten'
 b'tion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/l'
 b'ayer_norm_16/custom_model_2/self_attention_encoder_2/self_attention_encoder_'
 b'layer_2/transformer_layer_wrapper_11/layer_norm_16/gamma/m\x1ahmodel/encode'
 b'r/layers/0/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTE'
 b'S/VARIABLE_VALUE*\x02\x08\x01\n\xed\x02\x12\xe6\x02\n\x0eVARIABLE_VAL'
 b'UE\x12\xea\x01custom_model_2/self_attention_encoder_2/self_attention_enco'
 b'der_layer_2/transformer_layer_wrapper_11/layer_norm_16/custom_model_2/self_a'
 b'ttention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_'
 b'11/layer_norm_16/beta/m\x1agmodel/encoder/layers/0/ffn/input_layer_norm/bet'
 b'a/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa3\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_12/multi_head_attention_7/custom_model_2/self_attention_decoder_2/self_att'
 b'ention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/r'
 b'elative_position_keys/m\x1aymodel/decoder/layers/0/self_attention/layer/rel'
 b'ative_position_keys/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VAL'
 b'UE*\x02\x08\x01\n\xa7\x03\x12\xa0\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custo'
 b'm_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transforme'
 b'r_layer_wrapper_12/multi_head_attention_7/custom_model_2/self_attention_deco'
 b'der_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head'
 b'_attention_7/relative_position_values/m\x1a{model/decoder/layers/0/self_att'
 b'ention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTE'
 b'S/VARIABLE_VALUE*\x02\x08\x01\n\xfa\x02\x12\xf3\x02\n\x0eVARIABLE_VAL'
 b'UE\x12\xeb\x01custom_model_2/self_attention_decoder_2/self_attention_deco'
 b'der_layer_2/transformer_layer_wrapper_12/layer_norm_18/custom_model_2/self_a'
 b'ttention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_'
 b'12/layer_norm_18/gamma/m\x1asmodel/decoder/layers/0/self_attention/input_la'
 b'yer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\xf8\x02\x12\xf1\x02\n\x0eVARIABLE_VALUE\x12\xea\x01custom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_12/layer_norm_18/custom_model_2/self_attention_decoder_2/self'
 b'_attention_decoder_layer_2/transformer_layer_wrapper_12/layer_norm_18/beta/m'
 b'\x1armodel/decoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZER'
 b'_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xef\x02\x12'
 b'\xe8\x02\n\x0eVARIABLE_VALUE\x12\xeb\x01custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/layer_norm_'
 b'20/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/tr'
 b'ansformer_layer_wrapper_14/layer_norm_20/gamma/m\x1ahmodel/decoder/layers/0'
 b'/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE'
 b'_VALUE*\x02\x08\x01\n\xed\x02\x12\xe6\x02\n\x0eVARIABLE_VALUE\x12\xea\x01c'
 b'ustom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transf'
 b'ormer_layer_wrapper_14/layer_norm_20/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_14/layer_norm_20/b'
 b'eta/m\x1agmodel/decoder/layers/0/ffn/input_layer_norm/beta/.OPTIMIZER_SLOT/'
 b'optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa4\x03\x12\x9d\x03'
 b'\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self_attention_encoder_2/s'
 b'elf_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attent'
 b'ion_6/dense_33/custom_model_2/self_attention_encoder_2/self_attention_encode'
 b'r_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/dense_33/kerne'
 b'l/m\x1axmodel/encoder/layers/0/self_attention/layer/linear_queries/kernel/.'
 b'OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa0\x03'
 b'\x12\x99\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_attention_'
 b'encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_'
 b'head_attention_6/dense_33/custom_model_2/self_attention_encoder_2/self_atten'
 b'tion_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/den'
 b'se_33/bias/m\x1avmodel/encoder/layers/0/self_attention/layer/linear_queries'
 b'/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa1\x03\x12\x9a\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self'
 b'_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrappe'
 b'r_10/multi_head_attention_6/dense_34/custom_model_2/self_attention_encoder_2'
 b'/self_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_atte'
 b'ntion_6/dense_34/kernel/m\x1aumodel/encoder/layers/0/self_attention/layer/l'
 b'inear_keys/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x9d\x03\x12\x96\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_'
 b'model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_'
 b'layer_wrapper_10/multi_head_attention_6/dense_34/custom_model_2/self_attenti'
 b'on_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/mul'
 b'ti_head_attention_6/dense_34/bias/m\x1asmodel/encoder/layers/0/self_attenti'
 b'on/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_V'
 b'ALUE*\x02\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x90\x02cus'
 b'tom_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transfor'
 b'mer_layer_wrapper_10/multi_head_attention_6/dense_35/custom_model_2/self_att'
 b'ention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10'
 b'/multi_head_attention_6/dense_35/kernel/m\x1awmodel/encoder/layers/0/self_a'
 b'ttention/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/'
 b'VARIABLE_VALUE*\x02\x08\x01\n\x9f\x03\x12\x98\x03\n\x0eVARIABLE_VALUE'
 b'\x12\x8e\x02custom_model_2/self_attention_encoder_2/self_attention_encode'
 b'r_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/dense_35/custo'
 b'm_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transforme'
 b'r_layer_wrapper_10/multi_head_attention_6/dense_35/bias/m\x1aumodel/encoder'
 b'/layers/0/self_attention/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/'
 b'm/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARI'
 b'ABLE_VALUE\x12\x90\x02custom_model_2/self_attention_encoder_2/self_attent'
 b'ion_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/dens'
 b'e_36/custom_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/'
 b'transformer_layer_wrapper_10/multi_head_attention_6/dense_36/kernel/m\x1awm'
 b'odel/encoder/layers/0/self_attention/layer/linear_output/kernel/.OPTIMIZER_S'
 b'LOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x9f'
 b'\x03\x12\x98\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_atten'
 b'tion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/m'
 b'ulti_head_attention_6/dense_36/custom_model_2/self_attention_encoder_2/self_'
 b'attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attention_'
 b'6/dense_36/bias/m\x1aumodel/encoder/layers/0/self_attention/layer/linear_ou'
 b'tput/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_'
 b'model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_'
 b'layer_wrapper_11/feed_forward_network_4/dense_37/custom_model_2/self_attenti'
 b'on_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/fee'
 b'd_forward_network_4/dense_37/kernel/m\x1admodel/encoder/layers/0/ffn/layer/'
 b'inner/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_m'
 b'odel_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_l'
 b'ayer_wrapper_11/feed_forward_network_4/dense_37/custom_model_2/self_attentio'
 b'n_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/feed'
 b'_forward_network_4/dense_37/bias/m\x1abmodel/encoder/layers/0/ffn/layer/inn'
 b'er/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_'
 b'2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_'
 b'wrapper_11/feed_forward_network_4/dense_38/custom_model_2/self_attention_enc'
 b'oder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/feed_forw'
 b'ard_network_4/dense_38/kernel/m\x1admodel/encoder/layers/0/ffn/layer/outer/'
 b'kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08'
 b'\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/sel'
 b'f_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapp'
 b'er_11/feed_forward_network_4/dense_38/custom_model_2/self_attention_encoder_'
 b'2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/feed_forward_n'
 b'etwork_4/dense_38/bias/m\x1abmodel/encoder/layers/0/ffn/layer/outer/bias/.O'
 b'PTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa4\x03\x12\x9d\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_12/multi_head_attention_7/dense_39/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_atte'
 b'ntion_7/dense_39/kernel/m\x1axmodel/decoder/layers/0/self_attention/layer/l'
 b'inear_queries/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\n\xa0\x03\x12\x99\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_m'
 b'odel_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_l'
 b'ayer_wrapper_12/multi_head_attention_7/dense_39/custom_model_2/self_attentio'
 b'n_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/mult'
 b'i_head_attention_7/dense_39/bias/m\x1avmodel/decoder/layers/0/self_attentio'
 b'n/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE'
 b'_VALUE*\x02\x08\x01\n\xa1\x03\x12\x9a\x03\n\x0eVARIABLE_VALUE\x12\x90\x02c'
 b'ustom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transf'
 b'ormer_layer_wrapper_12/multi_head_attention_7/dense_40/custom_model_2/self_a'
 b'ttention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_'
 b'12/multi_head_attention_7/dense_40/kernel/m\x1aumodel/decoder/layers/0/self'
 b'_attention/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/'
 b'VARIABLE_VALUE*\x02\x08\x01\n\x9d\x03\x12\x96\x03\n\x0eVARIABLE_VALUE'
 b'\x12\x8e\x02custom_model_2/self_attention_decoder_2/self_attention_decode'
 b'r_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/dense_40/custo'
 b'm_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transforme'
 b'r_layer_wrapper_12/multi_head_attention_7/dense_40/bias/m\x1asmodel/decoder'
 b'/layers/0/self_attention/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/m/'
 b'.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARIAB'
 b'LE_VALUE\x12\x90\x02custom_model_2/self_attention_decoder_2/self_attentio'
 b'n_decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/dense_'
 b'41/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/tr'
 b'ansformer_layer_wrapper_12/multi_head_attention_7/dense_41/kernel/m\x1awmod'
 b'el/decoder/layers/0/self_attention/layer/linear_values/kernel/.OPTIMIZER_SLO'
 b'T/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x9f\x03\x12'
 b'\x98\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_'
 b'attention_7/dense_41/custom_model_2/self_attention_decoder_2/self_attention_'
 b'decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/dense_41'
 b'/bias/m\x1aumodel/decoder/layers/0/self_attention/layer/linear_values/bias/'
 b'.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa3'
 b'\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self_atten'
 b'tion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/m'
 b'ulti_head_attention_7/dense_42/custom_model_2/self_attention_decoder_2/self_'
 b'attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_'
 b'7/dense_42/kernel/m\x1awmodel/decoder/layers/0/self_attention/layer/linear_'
 b'output/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x9f\x03\x12\x98\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_'
 b'model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_'
 b'layer_wrapper_12/multi_head_attention_7/dense_42/custom_model_2/self_attenti'
 b'on_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/mul'
 b'ti_head_attention_7/dense_42/bias/m\x1aumodel/decoder/layers/0/self_attenti'
 b'on/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE'
 b'_VALUE*\x02\x08\x01\n\xf7\x02\x12\xf0\x02\n\x0eVARIABLE_VALUE\x12\xeb\x01c'
 b'ustom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transf'
 b'ormer_layer_wrapper_13/layer_norm_19/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_13/layer_norm_19/g'
 b'amma/m\x1apmodel/decoder/layers/0/attention/0/input_layer_norm/gamma/.OPTIM'
 b'IZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xf5\x02\x12'
 b'\xee\x02\n\x0eVARIABLE_VALUE\x12\xea\x01custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/layer_norm_'
 b'19/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/tr'
 b'ansformer_layer_wrapper_13/layer_norm_19/beta/m\x1aomodel/decoder/layers/0/'
 b'attention/0/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VA'
 b'RIABLE_VALUE*\x02\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90'
 b'\x02custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/'
 b'transformer_layer_wrapper_14/feed_forward_network_5/dense_47/custom_model_2/'
 b'self_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wr'
 b'apper_14/feed_forward_network_5/dense_47/kernel/m\x1admodel/decoder/layers/'
 b'0/ffn/layer/inner/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VA'
 b'LUE*\x02\x08\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02cust'
 b'om_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transform'
 b'er_layer_wrapper_14/feed_forward_network_5/dense_47/custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/'
 b'feed_forward_network_5/dense_47/bias/m\x1abmodel/decoder/layers/0/ffn/layer'
 b'/inner/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_'
 b'2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_'
 b'wrapper_14/feed_forward_network_5/dense_48/custom_model_2/self_attention_dec'
 b'oder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/feed_forw'
 b'ard_network_5/dense_48/kernel/m\x1admodel/decoder/layers/0/ffn/layer/outer/'
 b'kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08'
 b'\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/sel'
 b'f_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapp'
 b'er_14/feed_forward_network_5/dense_48/custom_model_2/self_attention_decoder_'
 b'2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/feed_forward_n'
 b'etwork_5/dense_48/bias/m\x1abmodel/decoder/layers/0/ffn/layer/outer/bias/.O'
 b'PTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa1\x03\x12\x9a\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_13/multi_head_attention_8/dense_43/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_13/multi_head_atte'
 b'ntion_8/dense_43/kernel/m\x1aumodel/decoder/layers/0/attention/0/layer/line'
 b'ar_queries/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x9d\x03\x12\x96\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_'
 b'model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_'
 b'layer_wrapper_13/multi_head_attention_8/dense_43/custom_model_2/self_attenti'
 b'on_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/mul'
 b'ti_head_attention_8/dense_43/bias/m\x1asmodel/decoder/layers/0/attention/0/'
 b'layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_V'
 b'ALUE*\x02\x08\x01\n\x9e\x03\x12\x97\x03\n\x0eVARIABLE_VALUE\x12\x90\x02cus'
 b'tom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transfor'
 b'mer_layer_wrapper_13/multi_head_attention_8/dense_44/custom_model_2/self_att'
 b'ention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13'
 b'/multi_head_attention_8/dense_44/kernel/m\x1armodel/decoder/layers/0/attent'
 b'ion/0/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIA'
 b'BLE_VALUE*\x02\x08\x01\n\x9a\x03\x12\x93\x03\n\x0eVARIABLE_VALUE\x12'
 b'\x8e\x02custom_model_2/self_attention_decoder_2/self_attention_decoder_lay'
 b'er_2/transformer_layer_wrapper_13/multi_head_attention_8/dense_44/custom_mod'
 b'el_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_lay'
 b'er_wrapper_13/multi_head_attention_8/dense_44/bias/m\x1apmodel/decoder/laye'
 b'rs/0/attention/0/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBU'
 b'TES/VARIABLE_VALUE*\x02\x08\x01\n\xa0\x03\x12\x99\x03\n\x0eVARIABLE_VALUE'
 b'\x12\x90\x02custom_model_2/self_attention_decoder_2/self_attention_decode'
 b'r_layer_2/transformer_layer_wrapper_13/multi_head_attention_8/dense_45/custo'
 b'm_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transforme'
 b'r_layer_wrapper_13/multi_head_attention_8/dense_45/kernel/m\x1atmodel/decod'
 b'er/layers/0/attention/0/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer'
 b'/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x9c\x03\x12\x95\x03\n\x0eVAR'
 b'IABLE_VALUE\x12\x8e\x02custom_model_2/self_attention_decoder_2/self_atten'
 b'tion_decoder_layer_2/transformer_layer_wrapper_13/multi_head_attention_8/den'
 b'se_45/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2'
 b'/transformer_layer_wrapper_13/multi_head_attention_8/dense_45/bias/m\x1armo'
 b'del/decoder/layers/0/attention/0/layer/linear_values/bias/.OPTIMIZER_SLOT/op'
 b'timizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa0\x03\x12'
 b'\x99\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/multi_head_'
 b'attention_8/dense_46/custom_model_2/self_attention_decoder_2/self_attention_'
 b'decoder_layer_2/transformer_layer_wrapper_13/multi_head_attention_8/dense_46'
 b'/kernel/m\x1atmodel/decoder/layers/0/attention/0/layer/linear_output/kernel'
 b'/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\x9c\x03\x12\x95\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/'
 b'multi_head_attention_8/dense_46/custom_model_2/self_attention_decoder_2/self'
 b'_attention_decoder_layer_2/transformer_layer_wrapper_13/multi_head_attention'
 b'_8/dense_46/bias/m\x1armodel/decoder/layers/0/attention/0/layer/linear_outp'
 b'ut/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\xae\x01\x12\xa7\x01\n\x0eVARIABLE_VALUE\x12)custom_model_2/cus'
 b'tom_model_2/embedding/v\x1ajmodel/examples_inputter/features_inputter/embed'
 b'ding/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\xac\x01\x12\xa5\x01\n\x0eVARIABLE_VALUE\x12)custom_model_2/custom_model_2'
 b'/embedding/v\x1ahmodel/examples_inputter/labels_inputter/embedding/.OPTIMIZ'
 b'ER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xe3'
 b'\x01\x12\xdc\x01\n\x0eVARIABLE_VALUE\x12scustom_model_2/self_attention_enco'
 b'der_2/layer_norm_14/custom_model_2/self_attention_encoder_2/layer_norm_14/ga'
 b'mma/v\x1aUmodel/encoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRI'
 b'BUTES/VARIABLE_VALUE*\x02\x08\x01\n\xe1\x01\x12\xda\x01\n\x0eVARIABLE_VAL'
 b'UE\x12rcustom_model_2/self_attention_encoder_2/layer_norm_14/custom_model_2'
 b'/self_attention_encoder_2/layer_norm_14/beta/v\x1aTmodel/encoder/layer_norm'
 b'/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xe3\x01\x12\xdc\x01\n\x0eVARIABLE_VALUE\x12scustom_model_2/self_attentio'
 b'n_decoder_2/layer_norm_17/custom_model_2/self_attention_decoder_2/layer_norm'
 b'_17/gamma/v\x1aUmodel/decoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/'
 b'.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xe1\x01\x12\xda\x01\n\x0eVARIAB'
 b'LE_VALUE\x12rcustom_model_2/self_attention_decoder_2/layer_norm_17/custom_m'
 b'odel_2/self_attention_decoder_2/layer_norm_17/beta/v\x1aTmodel/decoder/laye'
 b'r_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\xdd\x01\x12\xd6\x01\n\x0eVARIABLE_VALUE\x12jcustom_model_2/sel'
 b'f_attention_decoder_2/dense_49/custom_model_2/self_attention_decoder_2/dense'
 b'_49/kernel/v\x1aXmodel/decoder/output_layer/kernel/.OPTIMIZER_SLOT/optimize'
 b'r/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xd9\x01\x12\xd2\x01\n\x0eVA'
 b'RIABLE_VALUE\x12hcustom_model_2/self_attention_decoder_2/dense_49/custom_mo'
 b'del_2/self_attention_decoder_2/dense_49/bias/v\x1aVmodel/decoder/output_lay'
 b'er/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_'
 b'2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_'
 b'wrapper_10/multi_head_attention_6/custom_model_2/self_attention_encoder_2/se'
 b'lf_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attenti'
 b'on_6/relative_position_keys/v\x1aymodel/encoder/layers/0/self_attention/lay'
 b'er/relative_position_keys/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_V'
 b'ALUE*\x02\x08\x01\n\xa7\x03\x12\xa0\x03\n\x0eVARIABLE_VALUE\x12\x90\x02cus'
 b'tom_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transfor'
 b'mer_layer_wrapper_10/multi_head_attention_6/custom_model_2/self_attention_en'
 b'coder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_he'
 b'ad_attention_6/relative_position_values/v\x1a{model/encoder/layers/0/self_a'
 b'ttention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBU'
 b'TES/VARIABLE_VALUE*\x02\x08\x01\n\xfa\x02\x12\xf3\x02\n\x0eVARIABLE_VALUE'
 b'\x12\xeb\x01custom_model_2/self_attention_encoder_2/self_attention_encode'
 b'r_layer_2/transformer_layer_wrapper_10/layer_norm_15/custom_model_2/self_att'
 b'ention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10'
 b'/layer_norm_15/gamma/v\x1asmodel/encoder/layers/0/self_attention/input_laye'
 b'r_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\n\xf8\x02\x12\xf1\x02\n\x0eVARIABLE_VALUE\x12\xea\x01custom_m'
 b'odel_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_l'
 b'ayer_wrapper_10/layer_norm_15/custom_model_2/self_attention_encoder_2/self_a'
 b'ttention_encoder_layer_2/transformer_layer_wrapper_10/layer_norm_15/beta'
 b'/v\x1armodel/encoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZ'
 b'ER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xef'
 b'\x02\x12\xe8\x02\n\x0eVARIABLE_VALUE\x12\xeb\x01custom_model_2/self_atten'
 b'tion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/l'
 b'ayer_norm_16/custom_model_2/self_attention_encoder_2/self_attention_encoder_'
 b'layer_2/transformer_layer_wrapper_11/layer_norm_16/gamma/v\x1ahmodel/encode'
 b'r/layers/0/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTE'
 b'S/VARIABLE_VALUE*\x02\x08\x01\n\xed\x02\x12\xe6\x02\n\x0eVARIABLE_VAL'
 b'UE\x12\xea\x01custom_model_2/self_attention_encoder_2/self_attention_enco'
 b'der_layer_2/transformer_layer_wrapper_11/layer_norm_16/custom_model_2/self_a'
 b'ttention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_'
 b'11/layer_norm_16/beta/v\x1agmodel/encoder/layers/0/ffn/input_layer_norm/bet'
 b'a/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa3\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_12/multi_head_attention_7/custom_model_2/self_attention_decoder_2/self_att'
 b'ention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/r'
 b'elative_position_keys/v\x1aymodel/decoder/layers/0/self_attention/layer/rel'
 b'ative_position_keys/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VAL'
 b'UE*\x02\x08\x01\n\xa7\x03\x12\xa0\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custo'
 b'm_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transforme'
 b'r_layer_wrapper_12/multi_head_attention_7/custom_model_2/self_attention_deco'
 b'der_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head'
 b'_attention_7/relative_position_values/v\x1a{model/decoder/layers/0/self_att'
 b'ention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTE'
 b'S/VARIABLE_VALUE*\x02\x08\x01\n\xfa\x02\x12\xf3\x02\n\x0eVARIABLE_VAL'
 b'UE\x12\xeb\x01custom_model_2/self_attention_decoder_2/self_attention_deco'
 b'der_layer_2/transformer_layer_wrapper_12/layer_norm_18/custom_model_2/self_a'
 b'ttention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_'
 b'12/layer_norm_18/gamma/v\x1asmodel/decoder/layers/0/self_attention/input_la'
 b'yer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALU'
 b'E*\x02\x08\x01\n\xf8\x02\x12\xf1\x02\n\x0eVARIABLE_VALUE\x12\xea\x01custom'
 b'_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer'
 b'_layer_wrapper_12/layer_norm_18/custom_model_2/self_attention_decoder_2/self'
 b'_attention_decoder_layer_2/transformer_layer_wrapper_12/layer_norm_18/beta/v'
 b'\x1armodel/decoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZER'
 b'_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xef\x02\x12'
 b'\xe8\x02\n\x0eVARIABLE_VALUE\x12\xeb\x01custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/layer_norm_'
 b'20/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/tr'
 b'ansformer_layer_wrapper_14/layer_norm_20/gamma/v\x1ahmodel/decoder/layers/0'
 b'/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE'
 b'_VALUE*\x02\x08\x01\n\xed\x02\x12\xe6\x02\n\x0eVARIABLE_VALUE\x12\xea\x01c'
 b'ustom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transf'
 b'ormer_layer_wrapper_14/layer_norm_20/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_14/layer_norm_20/b'
 b'eta/v\x1agmodel/decoder/layers/0/ffn/input_layer_norm/beta/.OPTIMIZER_SLOT/'
 b'optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa4\x03\x12\x9d\x03'
 b'\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self_attention_encoder_2/s'
 b'elf_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attent'
 b'ion_6/dense_33/custom_model_2/self_attention_encoder_2/self_attention_encode'
 b'r_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/dense_33/kerne'
 b'l/v\x1axmodel/encoder/layers/0/self_attention/layer/linear_queries/kernel/.'
 b'OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa0\x03'
 b'\x12\x99\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_attention_'
 b'encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_'
 b'head_attention_6/dense_33/custom_model_2/self_attention_encoder_2/self_atten'
 b'tion_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/den'
 b'se_33/bias/v\x1avmodel/encoder/layers/0/self_attention/layer/linear_queries'
 b'/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa1\x03\x12\x9a\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self'
 b'_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrappe'
 b'r_10/multi_head_attention_6/dense_34/custom_model_2/self_attention_encoder_2'
 b'/self_attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_atte'
 b'ntion_6/dense_34/kernel/v\x1aumodel/encoder/layers/0/self_attention/layer/l'
 b'inear_keys/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x9d\x03\x12\x96\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_'
 b'model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_'
 b'layer_wrapper_10/multi_head_attention_6/dense_34/custom_model_2/self_attenti'
 b'on_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/mul'
 b'ti_head_attention_6/dense_34/bias/v\x1asmodel/encoder/layers/0/self_attenti'
 b'on/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_V'
 b'ALUE*\x02\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x90\x02cus'
 b'tom_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transfor'
 b'mer_layer_wrapper_10/multi_head_attention_6/dense_35/custom_model_2/self_att'
 b'ention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10'
 b'/multi_head_attention_6/dense_35/kernel/v\x1awmodel/encoder/layers/0/self_a'
 b'ttention/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/'
 b'VARIABLE_VALUE*\x02\x08\x01\n\x9f\x03\x12\x98\x03\n\x0eVARIABLE_VALUE'
 b'\x12\x8e\x02custom_model_2/self_attention_encoder_2/self_attention_encode'
 b'r_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/dense_35/custo'
 b'm_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transforme'
 b'r_layer_wrapper_10/multi_head_attention_6/dense_35/bias/v\x1aumodel/encoder'
 b'/layers/0/self_attention/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/'
 b'v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARI'
 b'ABLE_VALUE\x12\x90\x02custom_model_2/self_attention_encoder_2/self_attent'
 b'ion_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attention_6/dens'
 b'e_36/custom_model_2/self_attention_encoder_2/self_attention_encoder_layer_2/'
 b'transformer_layer_wrapper_10/multi_head_attention_6/dense_36/kernel/v\x1awm'
 b'odel/encoder/layers/0/self_attention/layer/linear_output/kernel/.OPTIMIZER_S'
 b'LOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x9f'
 b'\x03\x12\x98\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_atten'
 b'tion_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_10/m'
 b'ulti_head_attention_6/dense_36/custom_model_2/self_attention_encoder_2/self_'
 b'attention_encoder_layer_2/transformer_layer_wrapper_10/multi_head_attention_'
 b'6/dense_36/bias/v\x1aumodel/encoder/layers/0/self_attention/layer/linear_ou'
 b'tput/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_'
 b'model_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_'
 b'layer_wrapper_11/feed_forward_network_4/dense_37/custom_model_2/self_attenti'
 b'on_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/fee'
 b'd_forward_network_4/dense_37/kernel/v\x1admodel/encoder/layers/0/ffn/layer/'
 b'inner/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_m'
 b'odel_2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_l'
 b'ayer_wrapper_11/feed_forward_network_4/dense_37/custom_model_2/self_attentio'
 b'n_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/feed'
 b'_forward_network_4/dense_37/bias/v\x1abmodel/encoder/layers/0/ffn/layer/inn'
 b'er/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_'
 b'2/self_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_'
 b'wrapper_11/feed_forward_network_4/dense_38/custom_model_2/self_attention_enc'
 b'oder_2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/feed_forw'
 b'ard_network_4/dense_38/kernel/v\x1admodel/encoder/layers/0/ffn/layer/outer/'
 b'kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08'
 b'\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/sel'
 b'f_attention_encoder_2/self_attention_encoder_layer_2/transformer_layer_wrapp'
 b'er_11/feed_forward_network_4/dense_38/custom_model_2/self_attention_encoder_'
 b'2/self_attention_encoder_layer_2/transformer_layer_wrapper_11/feed_forward_n'
 b'etwork_4/dense_38/bias/v\x1abmodel/encoder/layers/0/ffn/layer/outer/bias/.O'
 b'PTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa4\x03\x12\x9d\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_12/multi_head_attention_7/dense_39/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_atte'
 b'ntion_7/dense_39/kernel/v\x1axmodel/decoder/layers/0/self_attention/layer/l'
 b'inear_queries/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*'
 b'\x02\x08\x01\n\xa0\x03\x12\x99\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_m'
 b'odel_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_l'
 b'ayer_wrapper_12/multi_head_attention_7/dense_39/custom_model_2/self_attentio'
 b'n_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/mult'
 b'i_head_attention_7/dense_39/bias/v\x1avmodel/decoder/layers/0/self_attentio'
 b'n/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE'
 b'_VALUE*\x02\x08\x01\n\xa1\x03\x12\x9a\x03\n\x0eVARIABLE_VALUE\x12\x90\x02c'
 b'ustom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transf'
 b'ormer_layer_wrapper_12/multi_head_attention_7/dense_40/custom_model_2/self_a'
 b'ttention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_'
 b'12/multi_head_attention_7/dense_40/kernel/v\x1aumodel/decoder/layers/0/self'
 b'_attention/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/'
 b'VARIABLE_VALUE*\x02\x08\x01\n\x9d\x03\x12\x96\x03\n\x0eVARIABLE_VALUE'
 b'\x12\x8e\x02custom_model_2/self_attention_decoder_2/self_attention_decode'
 b'r_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/dense_40/custo'
 b'm_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transforme'
 b'r_layer_wrapper_12/multi_head_attention_7/dense_40/bias/v\x1asmodel/decoder'
 b'/layers/0/self_attention/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/v/'
 b'.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa3\x03\x12\x9c\x03\n\x0eVARIAB'
 b'LE_VALUE\x12\x90\x02custom_model_2/self_attention_decoder_2/self_attentio'
 b'n_decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/dense_'
 b'41/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/tr'
 b'ansformer_layer_wrapper_12/multi_head_attention_7/dense_41/kernel/v\x1awmod'
 b'el/decoder/layers/0/self_attention/layer/linear_values/kernel/.OPTIMIZER_SLO'
 b'T/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x9f\x03\x12'
 b'\x98\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_'
 b'attention_7/dense_41/custom_model_2/self_attention_decoder_2/self_attention_'
 b'decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_7/dense_41'
 b'/bias/v\x1aumodel/decoder/layers/0/self_attention/layer/linear_values/bias/'
 b'.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa3'
 b'\x03\x12\x9c\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self_atten'
 b'tion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/m'
 b'ulti_head_attention_7/dense_42/custom_model_2/self_attention_decoder_2/self_'
 b'attention_decoder_layer_2/transformer_layer_wrapper_12/multi_head_attention_'
 b'7/dense_42/kernel/v\x1awmodel/decoder/layers/0/self_attention/layer/linear_'
 b'output/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x9f\x03\x12\x98\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_'
 b'model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_'
 b'layer_wrapper_12/multi_head_attention_7/dense_42/custom_model_2/self_attenti'
 b'on_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_12/mul'
 b'ti_head_attention_7/dense_42/bias/v\x1aumodel/decoder/layers/0/self_attenti'
 b'on/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE'
 b'_VALUE*\x02\x08\x01\n\xf7\x02\x12\xf0\x02\n\x0eVARIABLE_VALUE\x12\xeb\x01c'
 b'ustom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transf'
 b'ormer_layer_wrapper_13/layer_norm_19/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_13/layer_norm_19/g'
 b'amma/v\x1apmodel/decoder/layers/0/attention/0/input_layer_norm/gamma/.OPTIM'
 b'IZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xf5\x02\x12'
 b'\xee\x02\n\x0eVARIABLE_VALUE\x12\xea\x01custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/layer_norm_'
 b'19/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/tr'
 b'ansformer_layer_wrapper_13/layer_norm_19/beta/v\x1aomodel/decoder/layers/0/'
 b'attention/0/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VA'
 b'RIABLE_VALUE*\x02\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90'
 b'\x02custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/'
 b'transformer_layer_wrapper_14/feed_forward_network_5/dense_47/custom_model_2/'
 b'self_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wr'
 b'apper_14/feed_forward_network_5/dense_47/kernel/v\x1admodel/decoder/layers/'
 b'0/ffn/layer/inner/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VA'
 b'LUE*\x02\x08\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02cust'
 b'om_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transform'
 b'er_layer_wrapper_14/feed_forward_network_5/dense_47/custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/'
 b'feed_forward_network_5/dense_47/bias/v\x1abmodel/decoder/layers/0/ffn/layer'
 b'/inner/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02'
 b'\x08\x01\n\x90\x03\x12\x89\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_'
 b'2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_'
 b'wrapper_14/feed_forward_network_5/dense_48/custom_model_2/self_attention_dec'
 b'oder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/feed_forw'
 b'ard_network_5/dense_48/kernel/v\x1admodel/decoder/layers/0/ffn/layer/outer/'
 b'kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08'
 b'\x01\n\x8c\x03\x12\x85\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/sel'
 b'f_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapp'
 b'er_14/feed_forward_network_5/dense_48/custom_model_2/self_attention_decoder_'
 b'2/self_attention_decoder_layer_2/transformer_layer_wrapper_14/feed_forward_n'
 b'etwork_5/dense_48/bias/v\x1abmodel/decoder/layers/0/ffn/layer/outer/bias/.O'
 b'PTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01'
 b'\n\xa1\x03\x12\x9a\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self'
 b'_attention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrappe'
 b'r_13/multi_head_attention_8/dense_43/custom_model_2/self_attention_decoder_2'
 b'/self_attention_decoder_layer_2/transformer_layer_wrapper_13/multi_head_atte'
 b'ntion_8/dense_43/kernel/v\x1aumodel/decoder/layers/0/attention/0/layer/line'
 b'ar_queries/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE'
 b'*\x02\x08\x01\n\x9d\x03\x12\x96\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_'
 b'model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_'
 b'layer_wrapper_13/multi_head_attention_8/dense_43/custom_model_2/self_attenti'
 b'on_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/mul'
 b'ti_head_attention_8/dense_43/bias/v\x1asmodel/decoder/layers/0/attention/0/'
 b'layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_V'
 b'ALUE*\x02\x08\x01\n\x9e\x03\x12\x97\x03\n\x0eVARIABLE_VALUE\x12\x90\x02cus'
 b'tom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transfor'
 b'mer_layer_wrapper_13/multi_head_attention_8/dense_44/custom_model_2/self_att'
 b'ention_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13'
 b'/multi_head_attention_8/dense_44/kernel/v\x1armodel/decoder/layers/0/attent'
 b'ion/0/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIA'
 b'BLE_VALUE*\x02\x08\x01\n\x9a\x03\x12\x93\x03\n\x0eVARIABLE_VALUE\x12'
 b'\x8e\x02custom_model_2/self_attention_decoder_2/self_attention_decoder_lay'
 b'er_2/transformer_layer_wrapper_13/multi_head_attention_8/dense_44/custom_mod'
 b'el_2/self_attention_decoder_2/self_attention_decoder_layer_2/transformer_lay'
 b'er_wrapper_13/multi_head_attention_8/dense_44/bias/v\x1apmodel/decoder/laye'
 b'rs/0/attention/0/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBU'
 b'TES/VARIABLE_VALUE*\x02\x08\x01\n\xa0\x03\x12\x99\x03\n\x0eVARIABLE_VALUE'
 b'\x12\x90\x02custom_model_2/self_attention_decoder_2/self_attention_decode'
 b'r_layer_2/transformer_layer_wrapper_13/multi_head_attention_8/dense_45/custo'
 b'm_model_2/self_attention_decoder_2/self_attention_decoder_layer_2/transforme'
 b'r_layer_wrapper_13/multi_head_attention_8/dense_45/kernel/v\x1atmodel/decod'
 b'er/layers/0/attention/0/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer'
 b'/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\x9c\x03\x12\x95\x03\n\x0eVAR'
 b'IABLE_VALUE\x12\x8e\x02custom_model_2/self_attention_decoder_2/self_atten'
 b'tion_decoder_layer_2/transformer_layer_wrapper_13/multi_head_attention_8/den'
 b'se_45/custom_model_2/self_attention_decoder_2/self_attention_decoder_layer_2'
 b'/transformer_layer_wrapper_13/multi_head_attention_8/dense_45/bias/v\x1armo'
 b'del/decoder/layers/0/attention/0/layer/linear_values/bias/.OPTIMIZER_SLOT/op'
 b'timizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n\xa0\x03\x12'
 b'\x99\x03\n\x0eVARIABLE_VALUE\x12\x90\x02custom_model_2/self_attention_decod'
 b'er_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/multi_head_'
 b'attention_8/dense_46/custom_model_2/self_attention_decoder_2/self_attention_'
 b'decoder_layer_2/transformer_layer_wrapper_13/multi_head_attention_8/dense_46'
 b'/kernel/v\x1atmodel/decoder/layers/0/attention/0/layer/linear_output/kernel'
 b'/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01\n'
 b'\x9c\x03\x12\x95\x03\n\x0eVARIABLE_VALUE\x12\x8e\x02custom_model_2/self_atte'
 b'ntion_decoder_2/self_attention_decoder_layer_2/transformer_layer_wrapper_13/'
 b'multi_head_attention_8/dense_46/custom_model_2/self_attention_decoder_2/self'
 b'_attention_decoder_layer_2/transformer_layer_wrapper_13/multi_head_attention'
 b'_8/dense_46/bias/v\x1armodel/decoder/layers/0/attention/0/layer/linear_outp'
 b'ut/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE*\x02\x08\x01')
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.00121615,  0.00255418,  0.00151272,  0.0004299 ],
       [ 0.00083911, -0.00920208, -0.00852108, -0.00412674],
       [-0.00356357, -0.00084206, -0.00273739, -0.0027795 ],
       [ 0.00393605,  0.00749099,  0.00975538,  0.006481  ]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00087315,  0.00156813, -0.01321164,  0.00635776], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00721006, -0.00567761, -0.01421914, -0.00390441], dtype=float32)
-----------------------------------------------------------------------------------------------------------
optimizer/decay/.ATTRIBUTES/VARIABLE_VALUE
0.0
-----------------------------------------------------------------------------------------------------------
model/decoder/output_layer/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.01343215,  0.01407202, -0.1089045 ,  0.01727968, -0.01907185,
        0.02090694,  0.01875814,  0.03074492, -0.11269151, -0.01833417,
       -0.01782746,  0.01459359,  0.03306631,  0.02169868,  0.01821656,
        0.01640625,  0.02074234, -0.0678797 ,  0.02461874,  0.0124991 ,
        0.02467426,  0.01835871,  0.01743794,  0.01670095,  0.01833801,
       -0.02788034], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([4.07996922e-05, 1.21203057e-05, 1.34962365e-05, 9.83661721e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00333289,  0.00492705, -0.02474536,  0.01099128], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[1.9417908e-05, 2.7506621e-06, 1.4039976e-05, 4.4447411e-06],
       [1.2605096e-05, 5.1887318e-06, 6.7548126e-06, 2.2826364e-06],
       [7.7430712e-05, 4.4292097e-05, 3.3451994e-05, 1.0472171e-05],
       [1.4430398e-05, 2.0087722e-05, 6.6792345e-06, 2.4837359e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/relative_position_values/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.34925085, -0.0260371 ],
       [ 0.47065037, -0.19736558],
       [-0.2680002 , -0.15468702],
       [-0.41610175,  0.5540444 ],
       [ 0.31411815, -0.13942179],
       [ 0.2934696 , -0.10086744],
       [-0.20448013, -0.22084081],
       [-0.50508845, -0.03791578],
       [-0.05930802, -0.21763274],
       [-0.17690662, -0.17077196],
       [ 0.53702396,  0.27334946],
       [-0.14522055,  0.11108214],
       [-0.13636398, -0.12729582],
       [ 0.01558799, -0.16787359],
       [-0.31700635, -0.3115097 ],
       [-0.3430469 , -0.2913117 ],
       [-0.07010782, -0.32692015]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_values/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00049549,  0.00026022,  0.0004868 ,  0.00044326], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/inner/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00748378], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/input_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE
array([1.0002203, 1.0003059, 0.9998706, 0.9997405], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/output_layer/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.16568597,  0.3958109 , -0.07522207, -0.09532233, -0.08762556,
         0.21474135,  0.07746723, -0.3379547 ,  0.21657205, -0.18456693,
        -0.21583414,  0.2244643 , -0.40652388, -0.2055096 , -0.3581799 ,
        -0.09508283,  0.2732621 ,  0.3116807 ,  0.0831441 ,  0.2442727 ,
        -0.4167258 ,  0.43752858,  0.24314708,  0.3189785 ,  0.0806962 ,
        -0.0131554 ],
       [-0.42217982, -0.28158695,  0.2528372 ,  0.08774479,  0.0689019 ,
        -0.27626735, -0.34783548,  0.33799794,  0.07956316, -0.24859773,
         0.40171388,  0.15882143,  0.26308864, -0.0100828 , -0.31750998,
         0.16831186,  0.08814715,  0.3479909 ,  0.38343462, -0.29528803,
        -0.1557552 , -0.40747347,  0.16547954, -0.1936104 , -0.04652146,
        -0.3972933 ],
       [-0.14027077, -0.13444418, -0.39852476,  0.05985244,  0.08621543,
         0.38461822,  0.29514602,  0.19557235,  0.06249711,  0.26209012,
        -0.20832308,  0.16048849,  0.40081602,  0.34540385, -0.08407086,
        -0.40183136,  0.03178622,  0.33147565,  0.07177467, -0.16530696,
         0.44197416,  0.4323029 , -0.01903015,  0.11067788, -0.04427077,
         0.40260488],
       [ 0.25339144, -0.09003215, -0.32493222,  0.3813064 , -0.3771549 ,
        -0.30055124, -0.2507901 , -0.03980447,  0.1090384 , -0.39499432,
        -0.30618253,  0.3859604 ,  0.24572545,  0.16826957, -0.22843838,
         0.00165264, -0.40824032,  0.25137943, -0.33704758,  0.40789378,
         0.44611064, -0.1711505 , -0.18469664, -0.22045068, -0.34233302,
         0.30295828]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_queries/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[6.4685664e-05, 2.2053835e-05, 2.0914642e-06, 4.3882329e-07],
       [1.1803917e-05, 4.0036339e-06, 4.4597764e-06, 9.8634757e-07],
       [8.3796658e-06, 1.3041077e-06, 6.5461113e-06, 1.3177013e-06],
       [1.9281424e-05, 1.2478499e-05, 1.1789720e-05, 3.5972600e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00435234, -0.00202572, -0.01161642, -0.0066657 ], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.02174471, -0.01643386, -0.00376347, -0.016406  ], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.03406   , -0.06008913,  0.05171713,  0.01023528], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/input_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE
array([0.99950165, 0.99952626, 0.99967146, 0.9998561 ], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_output/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[1.0866081e-05, 6.3340980e-05, 1.1878528e-05, 1.0451040e-05],
       [1.8493488e-06, 6.9995058e-06, 1.5377292e-06, 7.3289095e-07],
       [3.3643689e-06, 6.8525455e-06, 1.2179437e-05, 1.6945321e-06],
       [1.4858712e-05, 3.3565895e-05, 6.1974992e-05, 7.3398319e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/input_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00043786, -0.00044357, -0.00044357,  0.00044359], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([5.4247441e-05, 2.3700262e-05, 3.7581469e-06, 4.2254233e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_queries/bias/.ATTRIBUTES/VARIABLE_VALUE
array([ 5.6978704e-05, -6.4164953e-05,  4.2930222e-04, -4.2317563e-04],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_keys/bias/.ATTRIBUTES/VARIABLE_VALUE
array([ 8.8884517e-05, -1.7489048e-04,  1.7123346e-04, -8.4076171e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/inner/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[5.8604008e-05],
       [2.9430537e-05],
       [6.6007509e-05],
       [2.6501330e-05]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_keys/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-1.1107132e-05,  7.7753226e-05, -8.0568389e-05,  1.2310837e-04],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/input_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE
array([0.00024535, 0.00019678, 0.00042338, 0.00027367], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_queries/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.02149043,  0.00949656, -0.00152762,  0.00202573],
       [-0.00763255, -0.00183849, -0.00519716,  0.00207095],
       [-0.00531826, -0.00263013, -0.00323821,  0.00116797],
       [-0.00854082, -0.00502451,  0.00996219, -0.00526456]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-3.0897365e-06,  1.9207564e-06,  4.1668372e-08,  1.6914021e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/inner/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.00622637],
       [ 0.01252606],
       [-0.0260914 ],
       [ 0.00734059]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([2.6992195e-06, 3.4427376e-06, 8.2959796e-06, 5.4106072e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_values/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.7400707 , -0.6497195 ,  0.44586897, -0.08460093],
       [-0.53840756, -0.46546453,  0.04610295,  0.5227031 ],
       [-0.40610123,  0.09011525, -0.76910585,  0.8209308 ],
       [-0.40531328,  0.80093193, -0.43916345,  0.40247118]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[2.0870222e-07, 5.8353631e-08, 8.5879492e-08, 3.1745014e-06],
       [3.9465641e-07, 2.8403138e-08, 2.0007600e-07, 4.7686613e-06],
       [9.7113514e-07, 2.2931248e-07, 2.4460453e-06, 2.7076929e-05],
       [6.9386965e-07, 1.7466775e-07, 1.4685509e-06, 2.3117900e-05]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_queries/bias/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00026152, -0.00044544,  0.00044584,  0.00044265], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_output/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00017532,  0.00051035, -0.00051186, -0.00049634], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([7.5394696e-06, 1.2960544e-05, 2.3370691e-05, 2.1551365e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_queries/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[2.4991207e-06, 2.9777673e-06, 3.9001147e-06, 8.4896823e-07],
       [9.8619503e-06, 1.1447794e-05, 2.0729061e-05, 4.6770174e-06],
       [4.7964414e-07, 4.9622128e-07, 2.9128055e-06, 7.5958849e-07],
       [1.0684133e-06, 1.2093409e-06, 1.6234890e-06, 2.9860121e-07]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.07961933, -0.00747257,  0.0421744 , -0.00441863], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([6.8439763e-06, 4.2436654e-06, 2.6611666e-05, 2.0066771e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([3.2264247e-04, 3.8596783e-05, 1.7269573e-04, 2.2724669e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/input_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE
array([ 3.7684815e-04, -3.2120912e-05,  4.8150873e-04,  1.9100811e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/input_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE
array([0.0003246 , 0.00032463, 0.00032459, 0.00032456], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_output/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.00521072, -0.01380731,  0.01264063, -0.00018692],
       [-0.00890253,  0.00969863, -0.00587331,  0.00156378],
       [ 0.0022303 , -0.03204636,  0.04011239,  0.00396315],
       [-0.00110907,  0.02248696, -0.02613334, -0.00373687]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_output/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.4984115 , -0.13047923,  0.75746965, -0.53834724],
       [ 0.7158481 ,  0.02947382, -0.65360606,  0.8436622 ],
       [-0.82060754,  0.4122568 , -0.08803061,  0.25756112],
       [-0.50625277,  0.37255412,  0.08346137,  0.3992973 ]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[1.0080701e-05, 1.5452480e-06, 2.0217091e-07, 1.9173260e-06],
       [6.5984518e-06, 3.7785123e-06, 2.2819397e-07, 2.5356775e-07],
       [6.8715517e-06, 4.3129480e-06, 9.2675702e-07, 2.7250924e-06],
       [1.2978891e-05, 2.4703634e-06, 5.2656276e-08, 1.8350850e-07]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([0.00966515, 0.013972  , 0.01919763, 0.00876891], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/relative_position_keys/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.00192926,  0.00586277],
       [ 0.00075173,  0.00016431],
       [-0.00251451, -0.00496064],
       [-0.00016559, -0.00106642],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_values/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-3.7585321e-04, -2.0854530e-04, -1.6041531e-04,  7.6473312e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([6.5091458e-06, 1.2262075e-05, 3.6558733e-05, 1.2066936e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00035352,  0.00048557,  0.00025348,  0.00030913], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-3.8986639e-07, -1.7145254e-07,  2.1258244e-07, -1.7995312e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.01370101, -0.00510549, -0.01151244, -0.00627613],
       [ 0.01228921, -0.00570311, -0.00465714, -0.00146971],
       [-0.03436568,  0.02186599,  0.01545848,  0.00571729],
       [ 0.0083946 , -0.01106606,  0.00070431,  0.00202606]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/input_layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE
array([1.5160778e-04, 2.0530397e-05, 3.1431785e-04, 1.3230393e-04],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_keys/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([7.5100611e-14, 1.4866401e-14, 3.0872922e-13, 1.4861876e-12],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_keys/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.54788274, -0.04265235,  0.58280194,  0.15397273],
       [-0.4721616 ,  0.26862472,  0.6895527 ,  0.0909343 ],
       [ 0.21176603, -0.36623046,  0.6542019 ,  0.63670814],
       [-0.8048772 ,  0.45451045, -0.3976652 ,  0.05919293]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 7.5929426e-03, -9.2691364e-04,  1.3373801e-03,  2.4200163e-03],
       [ 4.3202746e-03, -1.0181644e-03,  6.9138815e-04,  3.2284993e-04],
       [-2.0250499e-03, -1.8682145e-03, -2.0883246e-03, -3.0869481e-03],
       [-9.8847523e-03,  3.8122495e-03,  5.9586029e-05,  3.4277426e-04]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_keys/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 1.2829577e-03,  7.6087708e-05,  2.5185416e-04,  6.7623476e-03],
       [-2.3438386e-03, -2.6750070e-04, -1.2774380e-03, -8.8352263e-03],
       [ 4.0495843e-03,  1.6809029e-03,  5.0815451e-03,  1.9579303e-02],
       [-2.9893508e-03, -1.4906208e-03, -4.0575261e-03, -1.7513340e-02]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00665102, -0.05708835,  0.03993858,  0.01694445], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.01906063,  0.03469525,  0.00416316, -0.01256803], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_output/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.5503656 ,  0.12486798, -0.472403  ,  0.59639823],
       [-0.7506838 , -0.86093056, -0.54099566,  0.6559235 ],
       [ 0.37093008, -0.09707378, -0.01552279, -0.19002298],
       [ 0.8536917 , -0.2480853 , -0.7408335 , -0.08089484]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00767856,  0.00823083, -0.01110384, -0.00537613], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_queries/bias/.ATTRIBUTES/VARIABLE_VALUE
array([3.9918913e-04, 4.1612511e-04, 8.0745725e-05, 3.5915981e-04],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/output_layer/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([9.72124690e-06, 1.07350379e-05, 5.81990113e-04, 1.49429879e-05,
       1.82833101e-05, 2.20211805e-05, 1.75978093e-05, 4.78329712e-05,
       6.22910855e-04, 1.75642090e-05, 1.58482690e-05, 1.07050555e-05,
       5.51362646e-05, 2.34513191e-05, 1.63296172e-05, 1.37845345e-05,
       2.14835181e-05, 2.25795971e-04, 3.05413378e-05, 1.01897404e-05,
       3.01712498e-05, 1.66205355e-05, 1.49852831e-05, 1.38267405e-05,
       1.66155278e-05, 3.82849721e-05], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/inner/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([4.7877114e-05], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/output_layer/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.00670201,  0.0057236 ,  0.12314735, -0.01421024, -0.02207132,
        -0.00198823, -0.00414988, -0.03086117,  0.14135998, -0.05041971,
        -0.04077189, -0.00726106, -0.03776821, -0.01963828, -0.01238615,
        -0.00905557, -0.00069971, -0.03382721, -0.01166635,  0.00081491,
        -0.02789393,  0.00407507, -0.0031139 ,  0.00182125, -0.00389176,
         0.06141361],
       [ 0.00449756,  0.00038016, -0.08297872,  0.0090967 , -0.00182231,
         0.006622  ,  0.00657479,  0.02135803, -0.07502297,  0.01430086,
         0.01025637,  0.00589315,  0.02329112,  0.01299794,  0.00948086,
         0.00759002,  0.00709488, -0.00244406,  0.01337978,  0.00075087,
         0.01564416,  0.00275282,  0.00649831,  0.00364815,  0.00707648,
        -0.02693043],
       [ 0.00030896,  0.00043034, -0.05871191,  0.00427111, -0.02039784,
         0.01446113,  0.01237467,  0.02086199, -0.06929205, -0.00733199,
         0.00795457,  0.00301801,  0.02166033,  0.01343576,  0.01000232,
         0.0019062 ,  0.01170193, -0.00884079,  0.01643246, -0.00460321,
         0.01361242,  0.00993682,  0.0077104 ,  0.00730051,  0.0097642 ,
        -0.01796312],
       [ 0.00190317, -0.00653247,  0.01850868,  0.00085106,  0.04428387,
        -0.01909904, -0.01479617, -0.01134682,  0.00288907,  0.04347749,
         0.02254553, -0.0016438 , -0.00716414, -0.00679243, -0.00709147,
        -0.00043449, -0.01809677,  0.04510239, -0.01813986,  0.00304309,
        -0.00135385, -0.01676507, -0.01108918, -0.01276806, -0.01294713,
        -0.0165276 ]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_queries/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([3.6387926e-06, 4.0311684e-06, 9.2535583e-06, 2.1562364e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([2.3084004e-09, 1.1091894e-05, 9.8777573e-06, 1.1598741e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_queries/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.293235  , -0.13157767,  0.43993446,  0.27866226],
       [-0.13613941,  0.00557815,  0.15551777, -0.8435672 ],
       [-0.6017417 ,  0.69876945,  0.84996676,  0.3119081 ],
       [ 0.40393558,  0.15643215, -0.27004683, -0.1060132 ]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([4.1145458e-06, 2.0796897e-06, 1.3859464e-05, 7.4758650e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_queries/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.00610282, -0.00673438,  0.00647774,  0.00309094],
       [-0.01272702,  0.01401083, -0.01638929, -0.00787048],
       [ 0.00263659, -0.00281756,  0.00582518,  0.00301545],
       [ 0.0039814 , -0.00445232,  0.0040773 ,  0.00175886]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([2.1222353e-05, 8.6584056e-05, 1.1917783e-06, 2.1012016e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_output/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.01163852, -0.02726947,  0.00979628,  0.01044106],
       [-0.00529055,  0.01025801, -0.00449236, -0.00315267],
       [ 0.0072771 ,  0.00113687, -0.00979844,  0.00262603],
       [ 0.01531417,  0.00169308, -0.02070054,  0.00750956]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_values/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.4059084 , -0.24457172,  0.48633856, -0.40699062],
       [ 0.33164   , -0.10829678,  0.6499311 , -0.6677002 ],
       [ 0.7340199 , -0.29921436,  0.6733897 ,  0.19274122],
       [-0.36067367, -0.18822047,  0.24579805, -0.62698966]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/layer/inner/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.37803254],
       [-0.2978823 ],
       [-0.74548376],
       [-0.20480248]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_values/bias/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00029745, -0.00048485, -0.00045637,  0.00023646], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE
array([0.9996809 , 0.9999662 , 0.99963605, 1.0003296 ], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/linear_values/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[-7.3993844e-03, -8.6525800e-03,  2.9512811e-03,  9.2703272e-03],
       [ 9.3813709e-05,  2.2896355e-02, -2.5034531e-03, -1.9138988e-02],
       [-1.1718054e-02,  6.9226738e-04,  5.7772747e-03,  2.9631235e-02],
       [ 1.9025162e-02, -1.4931299e-02, -6.2280609e-03, -1.9793406e-02]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/inner/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 9.1811497e-05],
       [ 1.1762166e-02],
       [-5.4514580e-03],
       [-6.3991426e-03]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_keys/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-4.0738060e-04, -8.2423503e-06, -2.2142239e-04, -1.5482209e-04],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/relative_position_keys/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [2.31667656e-07, 2.30933733e-06],
       [9.67893996e-08, 1.11057631e-07],
       [3.64687253e-07, 2.33192327e-06],
       [1.08608795e-07, 1.93218213e-07],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_output/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[2.5495835e-06, 6.4403466e-05, 3.1764495e-05, 1.0343648e-05],
       [5.9519998e-06, 9.5285235e-05, 5.5746979e-05, 1.5578164e-05],
       [4.4703725e-06, 1.5967630e-04, 1.3521382e-04, 1.5884461e-05],
       [1.4700842e-06, 6.0555201e-05, 5.1694395e-05, 5.4003635e-06]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [-0.00156101,  0.00449682],
       [-0.00255129,  0.00431838],
       [-0.00805721, -0.0121849 ],
       [-0.00272751,  0.02549645],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ],
       [ 0.        ,  0.        ]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/output_layer/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-0.000515  , -0.00051429,  0.00052567, -0.00052456,  0.00052472,
       -0.00052034, -0.00052197, -0.00051935,  0.00052521,  0.00052187,
        0.00052527, -0.00052409, -0.00052203, -0.00052407, -0.0005252 ,
       -0.00052134, -0.00052029,  0.00052555, -0.00051663, -0.00048805,
       -0.00052601, -0.00052369, -0.00052372, -0.00052373, -0.00052271,
        0.0005233 ], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00381553, -0.00517694, -0.00498017,  0.00575025], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([1.6923800e-10, 1.9675113e-05, 2.5825384e-06, 1.3297779e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/output_layer/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[2.69653538e-06, 4.67087011e-06, 9.33006697e-04, 1.03916091e-05,
        6.64752661e-05, 3.07049572e-06, 3.04138598e-06, 5.02159673e-05,
        9.99607611e-04, 1.47683197e-04, 1.30667773e-04, 3.25500355e-06,
        7.41561526e-05, 2.05460765e-05, 8.70520762e-06, 4.62883236e-06,
        2.91938841e-06, 1.76494490e-04, 9.10108793e-06, 1.33492824e-06,
        3.99921482e-05, 4.11532437e-06, 2.28407384e-06, 2.68287590e-06,
        2.66659708e-06, 1.84273988e-04],
       [1.16596357e-06, 6.45415469e-07, 3.98810575e-04, 4.26710540e-06,
        1.27249796e-05, 3.12297698e-06, 2.89653235e-06, 2.40302506e-05,
        2.91644625e-04, 1.29819109e-05, 2.06189707e-05, 1.94591894e-06,
        2.83985191e-05, 9.00415398e-06, 4.91712899e-06, 3.07086270e-06,
        3.26737131e-06, 6.93957554e-05, 9.87118801e-06, 4.32151438e-07,
        1.26978275e-05, 1.26722489e-06, 2.60823072e-06, 1.28492150e-06,
        3.07513051e-06, 4.42141645e-05],
       [3.94337303e-06, 3.33221442e-06, 4.14503331e-04, 5.57197245e-06,
        3.06926013e-05, 1.51815193e-05, 1.17796744e-05, 3.05990798e-05,
        4.36744536e-04, 2.43819140e-05, 5.45330986e-05, 4.08525739e-06,
        3.36752892e-05, 1.44519663e-05, 9.11277039e-06, 4.88996375e-06,
        1.09237235e-05, 1.63979843e-04, 1.92556909e-05, 6.10071447e-06,
        1.60838554e-05, 8.45028717e-06, 6.46670060e-06, 5.83352085e-06,
        8.46127296e-06, 2.28207646e-05],
       [3.58282227e-06, 3.94741710e-06, 2.57276261e-04, 4.33960713e-06,
        1.26337298e-04, 2.07134090e-05, 1.31644401e-05, 1.26708965e-05,
        1.86587029e-04, 9.68541935e-05, 8.32338919e-05, 2.98505438e-06,
        1.01943269e-05, 6.24050472e-06, 5.38371842e-06, 4.01137686e-06,
        1.87972873e-05, 2.57031119e-04, 1.99709739e-05, 4.20253627e-06,
        5.86688930e-06, 1.55923153e-05, 8.32924616e-06, 9.86090799e-06,
        1.05965755e-05, 2.83083355e-05]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE
array([0.99949515, 1.0002987 , 0.9995698 , 0.9998225 ], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([1.0380400e-05, 6.7516230e-06, 1.0206501e-05, 4.9930684e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([5.6380509e-06, 1.6729126e-04, 1.0020307e-04, 2.6842494e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00204769, -0.05220809,  0.04446938,  0.01890881], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00010667,  0.00740187,  0.00698579, -0.00756968], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/outer/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[2.1804874e-04, 1.0319264e-04, 4.2084142e-05, 8.8634355e-05]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/input_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE
array([1.0002213 , 1.0004582 , 0.99954987, 1.0002831 ], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/inner/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([1.1338646e-05], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_output/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([2.9751733e-05, 1.5686132e-05, 1.1520254e-05, 7.0153555e-06],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 1.5092967e-06, -1.1618676e-02,  5.0869039e-03, -6.4657866e-03],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_output/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[-0.46023148, -0.83289236,  0.8482737 ,  0.20737892],
       [ 0.74878347,  0.35987458, -0.07286732,  0.22719638],
       [ 0.5020329 , -0.04767292, -0.68458855,  0.3731629 ],
       [ 0.38565594, -0.02913595, -0.7290557 ,  0.68018556]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/inner/kernel/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.01425852],
       [-0.98854256],
       [-0.93236583],
       [ 1.0109718 ]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/inner/kernel/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[8.3015919e-07],
       [2.0160393e-05],
       [2.9626913e-06],
       [1.3028038e-05]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/input_layer_norm/gamma/.ATTRIBUTES/VARIABLE_VALUE
array([1.0003436 , 1.0000573 , 0.99965215, 0.99988604], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/outer/bias/.ATTRIBUTES/VARIABLE_VALUE
array([-4.5797401e-04,  4.9181306e-04,  4.9523645e-05, -1.5659985e-04],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/attention/0/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([5.2084564e-05, 3.6538495e-05, 4.0173880e-05, 1.2236737e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layer_norm/beta/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00051338,  0.00052598, -0.00051889, -0.00010714], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/outer/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.02027682, -0.01515786, -0.00773576,  0.00691857], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/examples_inputter/labels_inputter/embedding/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.426385  , -0.42090976, -0.23256385, -0.26911724],
       [ 0.28286806, -0.01903239,  0.37325084, -0.37733585],
       [ 0.22005731, -0.37639123, -0.21890756,  0.4305262 ],
       [ 0.3281203 , -0.33143204,  0.18855405, -0.42441237],
       [-0.08168495,  0.25209552, -0.3864209 ,  0.43383658],
       [-0.11386219,  0.21491009,  0.4468584 ,  0.04573041],
       [-0.2041738 ,  0.33322066,  0.39263123,  0.08733767],
       [ 0.07841122,  0.40473628,  0.30672312,  0.0150696 ],
       [-0.12883621,  0.34524953, -0.01564494, -0.05788292],
       [ 0.0073111 , -0.17006245,  0.0860619 , -0.0951134 ],
       [-0.40562028,  0.371645  ,  0.23825182, -0.39595544],
       [-0.01579699, -0.3704266 , -0.07322544,  0.43140614],
       [ 0.0400449 , -0.13127273, -0.18405867,  0.16812819],
       [-0.08962154,  0.05518335,  0.10828632,  0.03638056],
       [ 0.12169808,  0.18249446,  0.14514625, -0.35726792],
       [-0.3982386 ,  0.41264606, -0.0276975 ,  0.0086441 ],
       [ 0.0162445 , -0.06555927,  0.35321307, -0.44710612],
       [-0.12248787, -0.04807037, -0.22313426, -0.00482849],
       [-0.19536465, -0.36221802, -0.26946855, -0.15109178],
       [-0.08454251,  0.18201673, -0.11034724, -0.20568298],
       [-0.42216015, -0.23068035,  0.44658333, -0.06286138],
       [ 0.03794643,  0.2001586 , -0.08569673,  0.27832872],
       [-0.2896335 ,  0.43570405, -0.3836738 ,  0.37995166],
       [ 0.42532814, -0.22403988,  0.11501598, -0.2002266 ],
       [-0.19803494, -0.11987698,  0.02486098, -0.2921996 ],
       [ 0.04149812,  0.08060095, -0.19622691, -0.11685528]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/layer/linear_values/bias/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([0.00212354, 0.00802712, 0.00852633, 0.00509376], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/self_attention/layer/relative_position_values/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([[0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [2.5881587e-07, 1.2212779e-06],
       [4.2468119e-07, 1.9571648e-06],
       [5.0216454e-06, 2.0338142e-05],
       [1.9834333e-06, 6.2456063e-05],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00],
       [0.0000000e+00, 0.0000000e+00]], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/ffn/layer/outer/kernel/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([[ 0.05668303, -0.03583828, -0.0183137 ,  0.01114961]],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/decoder/layers/0/ffn/input_layer_norm/gamma/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([-0.00234944, -0.00372981,  0.01946218, -0.00150113], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/m/.ATTRIBUTES/VARIABLE_VALUE
array([ 0.00239006, -0.00991477,  0.00150943, -0.00837098], dtype=float32)
-----------------------------------------------------------------------------------------------------------
model/encoder/layers/0/self_attention/input_layer_norm/beta/.OPTIMIZER_SLOT/optimizer/v/.ATTRIBUTES/VARIABLE_VALUE
array([8.4414423e-06, 1.7337310e-05, 2.8320479e-05, 1.9714782e-05],
      dtype=float32)
-----------------------------------------------------------------------------------------------------------
```
